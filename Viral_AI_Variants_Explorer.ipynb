{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "title"
   },
   "source": [
    "# ğŸ¦  Viral AI Variants Explorer\n",
    "\n",
    "This notebook demonstrates how to explore the **VirusSeq Variants** table on Viral AI using the Omics AI Explorer Python library.\n",
    "\n",
    "**Target Dataset**: `collections.virusseq.variants` on [viral.ai](https://viral.ai)\n",
    "\n",
    "## What we'll cover:\n",
    "- Connect to Viral AI network\n",
    "- Explore the VirusSeq collection\n",
    "- Query the variants table\n",
    "- Display the first 10 rows of variant data\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "setup"
   },
   "source": [
    "## ğŸ“¦ Setup and Installation\n",
    "\n",
    "First, let's install and import the Omics AI Explorer library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab_type": "code",
    "id": "install-package"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: pip\n",
      "âœ… Successfully imported OmicsAIClient!\n",
      "\n",
      "ğŸ¦  Viral AI Variants Explorer Ready!\n",
      "ğŸ“… Started at: 2025-06-11 09:34:59\n"
     ]
    }
   ],
   "source": [
    "# Install the Omics AI Explorer library\n",
    "!pip install git+https://github.com/mfiume/omics-ai-python-library.git --quiet\n",
    "\n",
    "# Import required libraries\n",
    "try:\n",
    "    from omics_ai import OmicsAIClient\n",
    "    print(\"âœ… Successfully imported OmicsAIClient!\")\n",
    "except ImportError:\n",
    "    print(\"âš ï¸ Package import failed, using fallback implementation...\")\n",
    "    \n",
    "    # Fallback implementation based on the working debug script\n",
    "    import requests\n",
    "    import json\n",
    "    import time\n",
    "    from typing import Dict, List, Optional, Any\n",
    "    from urllib.parse import quote\n",
    "    \n",
    "    def parse_json_lines_response(raw_text: str, debug: bool = False) -> Dict[str, Any]:\n",
    "        \"\"\"Parse JSON Lines response from Viral AI API.\"\"\"\n",
    "        if debug:\n",
    "            print(f\"ğŸ” Debug: Raw response length: {len(raw_text)}\")\n",
    "            print(f\"ğŸ” Debug: First 200 chars: {raw_text[:200]}\")\n",
    "            \n",
    "        if not raw_text.strip():\n",
    "            raise Exception(\"Empty response received\")\n",
    "        \n",
    "        # Split by lines and filter out empty lines\n",
    "        lines = [line.strip() for line in raw_text.strip().split('\\n') if line.strip()]\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"ğŸ” Debug: Found {len(lines)} non-empty lines\")\n",
    "            for i, line in enumerate(lines[:3]):\n",
    "                print(f\"ğŸ” Debug: Line {i+1}: {line[:100]}...\")\n",
    "        \n",
    "        if not lines:\n",
    "            raise Exception(\"No valid lines found in response\")\n",
    "        \n",
    "        # Parse each line as JSON\n",
    "        json_objects = []\n",
    "        for i, line in enumerate(lines):\n",
    "            try:\n",
    "                obj = json.loads(line)\n",
    "                json_objects.append(obj)\n",
    "                if debug:\n",
    "                    keys = list(obj.keys()) if obj else []\n",
    "                    print(f\"ğŸ” Debug: Parsed line {i+1}: keys={keys}\")\n",
    "                    if obj and 'data' in obj:\n",
    "                        print(f\"ğŸ” Debug: Line {i+1} has data array with {len(obj['data'])} items\")\n",
    "            except json.JSONDecodeError as e:\n",
    "                if debug:\n",
    "                    print(f\"ğŸ” Debug: Failed to parse line {i+1}: {e}\")\n",
    "                if line != \"{}\":\n",
    "                    print(f\"âš ï¸ Failed to parse line {i+1}: {line[:100]}... - {e}\")\n",
    "        \n",
    "        if not json_objects:\n",
    "            raise Exception(\"No valid JSON objects found in response\")\n",
    "        \n",
    "        # Find the object with data (usually the last non-empty one)\n",
    "        for obj in reversed(json_objects):\n",
    "            if obj and 'data' in obj:\n",
    "                if debug:\n",
    "                    print(f\"ğŸ” Debug: Found data object with {len(obj['data'])} rows\")\n",
    "                return obj\n",
    "        \n",
    "        # If no data object found, check for next_page_token (polling case)\n",
    "        for obj in reversed(json_objects):\n",
    "            if obj and 'next_page_token' in obj:\n",
    "                if debug:\n",
    "                    print(f\"ğŸ” Debug: Found next_page_token: {obj['next_page_token'][:50]}...\")\n",
    "                return obj\n",
    "        \n",
    "        # If we get here, we have only empty objects {} or unexpected format\n",
    "        if all(not obj for obj in json_objects):\n",
    "            if debug:\n",
    "                print(\"ğŸ” Debug: All objects are empty, treating as polling case\")\n",
    "            return {\"next_page_token\": \"empty_response_poll\"}\n",
    "        \n",
    "        # Return the last non-empty object\n",
    "        non_empty_objects = [obj for obj in json_objects if obj]\n",
    "        if non_empty_objects:\n",
    "            result = non_empty_objects[-1]\n",
    "            if debug:\n",
    "                print(f\"ğŸ” Debug: Returning last non-empty object with keys: {list(result.keys())}\")\n",
    "            return result\n",
    "        \n",
    "        raise Exception(f\"No data or next_page_token found. Objects: {json_objects}\")\n",
    "    \n",
    "    class OmicsAIClient:\n",
    "        \"\"\"Simplified Omics AI Explorer client for Viral AI.\"\"\"\n",
    "        \n",
    "        def __init__(self, network: str = \"viral.ai\"):\n",
    "            if not network.startswith(('http://', 'https://')):\n",
    "                network = f\"https://{network}\"\n",
    "            self.network = network.rstrip('/')\n",
    "            self.session = requests.Session()\n",
    "            self.session.headers.update({\n",
    "                'User-Agent': 'viral-ai-explorer/1.0',\n",
    "                'Accept': 'application/json',\n",
    "                'Content-Type': 'application/json'\n",
    "            })\n",
    "        \n",
    "        def _make_request(self, method: str, endpoint: str, **kwargs):\n",
    "            url = f\"{self.network}{endpoint}\"\n",
    "            response = self.session.request(method, url, **kwargs)\n",
    "            response.raise_for_status()\n",
    "            return response\n",
    "        \n",
    "        def list_collections(self) -> List[Dict[str, Any]]:\n",
    "            response = self._make_request('GET', '/api/collections')\n",
    "            return response.json()\n",
    "        \n",
    "        def list_tables(self, collection_slug: str) -> List[Dict[str, Any]]:\n",
    "            endpoint = f\"/api/collections/{quote(collection_slug)}/tables\"\n",
    "            response = self._make_request('GET', endpoint)\n",
    "            return response.json()\n",
    "        \n",
    "        def get_schema_fields(self, collection_slug: str, table_name: str) -> List[Dict[str, str]]:\n",
    "            endpoint = f\"/api/collection/{quote(collection_slug)}/data-connect/table/{quote(table_name)}/info\"\n",
    "            response = self._make_request('GET', endpoint)\n",
    "            schema = response.json()\n",
    "            \n",
    "            data_model = schema.get('data_model', {}).get('properties', {})\n",
    "            fields = []\n",
    "            for field_name, field_spec in data_model.items():\n",
    "                field_type = field_spec.get('type', '')\n",
    "                if isinstance(field_type, list):\n",
    "                    field_type = ', '.join(field_type)\n",
    "                if field_type == 'array' and 'items' in field_spec:\n",
    "                    item_type = field_spec['items'].get('type', '')\n",
    "                    if isinstance(item_type, list):\n",
    "                        item_type = ', '.join(item_type)\n",
    "                    field_type = f\"array<{item_type}>\"\n",
    "                \n",
    "                fields.append({\n",
    "                    'field': field_name,\n",
    "                    'type': field_type,\n",
    "                    'sql_type': field_spec.get('sqlType', '')\n",
    "                })\n",
    "            return fields\n",
    "        \n",
    "        def query_with_polling(self, collection_slug: str, table_name: str, \n",
    "                             filters=None, limit: int = 100, offset: int = 0,\n",
    "                             max_polls: int = 10, poll_interval: float = 2.0, \n",
    "                             debug: bool = False) -> Dict[str, Any]:\n",
    "            \"\"\"Query with polling for async results.\"\"\"\n",
    "            if filters is None:\n",
    "                filters = {}\n",
    "                \n",
    "            payload = {\n",
    "                \"tableName\": table_name,\n",
    "                \"filters\": filters,\n",
    "                \"pagination\": {\"limit\": limit, \"offset\": offset}\n",
    "            }\n",
    "            \n",
    "            endpoint = f\"/api/collections/{quote(collection_slug)}/tables/{quote(table_name)}/filter\"\n",
    "            \n",
    "            if debug:\n",
    "                print(f\"ğŸ” Debug: Endpoint: {self.network}{endpoint}\")\n",
    "                print(f\"ğŸ” Debug: Payload: {json.dumps(payload, indent=2)}\")\n",
    "            \n",
    "            print(f\"ğŸ”„ Starting async query (max {max_polls} polls, {poll_interval}s interval)...\")\n",
    "            \n",
    "            for poll_count in range(max_polls):\n",
    "                response = self._make_request('POST', endpoint, json=payload)\n",
    "                \n",
    "                if debug:\n",
    "                    print(f\"ğŸ” Debug: Poll {poll_count + 1} response status: {response.status_code}\")\n",
    "                \n",
    "                # Parse response\n",
    "                try:\n",
    "                    result = parse_json_lines_response(response.text, debug=debug)\n",
    "                except Exception as e:\n",
    "                    raise Exception(f\"Failed to parse response: {e}\")\n",
    "                \n",
    "                # Check if we have data or need to poll\n",
    "                if 'data' in result and isinstance(result['data'], list):\n",
    "                    print(f\"âœ… Data ready after {poll_count + 1} poll(s)!\")\n",
    "                    return result\n",
    "                elif 'next_page_token' in result or result.get('next_page_token') == 'empty_response_poll':\n",
    "                    print(f\"   Poll {poll_count + 1}/{max_polls}: Data not ready, polling again in {poll_interval}s...\")\n",
    "                    if result.get('next_page_token') != 'empty_response_poll':\n",
    "                        payload['next_page_token'] = result['next_page_token']\n",
    "                    time.sleep(poll_interval)\n",
    "                else:\n",
    "                    return result  # Return whatever we got\n",
    "            \n",
    "            raise Exception(f\"Query timed out after {max_polls} polls\")\n",
    "        \n",
    "        def query(self, collection_slug: str, table_name: str, filters=None, limit: int = 100, **kwargs) -> Dict[str, Any]:\n",
    "            \"\"\"Query with auto-polling.\"\"\"\n",
    "            return self.query_with_polling(collection_slug, table_name, filters=filters, limit=limit)\n",
    "    \n",
    "    print(\"âœ… Using fallback implementation with working JSON Lines parser!\")\n",
    "\n",
    "# Import data analysis libraries\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"\\nğŸ¦  Viral AI Variants Explorer Ready!\")\n",
    "print(f\"ğŸ“… Started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "connect"
   },
   "source": [
    "## ğŸ”— Connect to Viral AI\n",
    "\n",
    "Let's connect to the Viral AI network and explore what's available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab_type": "code",
    "id": "connect-viral-ai"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”— Connected to Viral AI!\n",
      "ğŸŒ Network: https://viral.ai\n",
      "âœ… Connection successful! Found 18 collections.\n",
      "\n",
      "ğŸ¯ Found VirusSeq collection:\n",
      "   ğŸ“‹ Name: VirusSeq SARS-CoV-2 Genome Sequences\n",
      "   ğŸ”— Slug: virusseq\n",
      "   ğŸ“ Description: <p>The&nbsp;mission&nbsp;of&nbsp;Canadian&nbsp;COVID&nbsp;Genomics&nbsp;Network&nbsp;(<a href=\"https...\n"
     ]
    }
   ],
   "source": [
    "# Create client for Viral AI\n",
    "client = OmicsAIClient(\"viral.ai\")\n",
    "\n",
    "print(\"ğŸ”— Connected to Viral AI!\")\n",
    "print(f\"ğŸŒ Network: {client.network}\")\n",
    "\n",
    "# Test basic connection\n",
    "try:\n",
    "    collections = client.list_collections()\n",
    "    print(f\"âœ… Connection successful! Found {len(collections)} collections.\")\n",
    "    \n",
    "    # Look for the virusseq collection\n",
    "    virusseq_collection = None\n",
    "    for collection in collections:\n",
    "        if collection.get('slugName') == 'virusseq':\n",
    "            virusseq_collection = collection\n",
    "            break\n",
    "    \n",
    "    if virusseq_collection:\n",
    "        print(f\"\\nğŸ¯ Found VirusSeq collection:\")\n",
    "        print(f\"   ğŸ“‹ Name: {virusseq_collection.get('name', 'N/A')}\")\n",
    "        print(f\"   ğŸ”— Slug: {virusseq_collection.get('slugName', 'N/A')}\")\n",
    "        print(f\"   ğŸ“ Description: {virusseq_collection.get('description', 'N/A')[:100]}...\")\n",
    "    else:\n",
    "        print(\"âŒ VirusSeq collection not found\")\n",
    "        print(\"Available collections:\")\n",
    "        for collection in collections[:5]:\n",
    "            print(f\"   - {collection.get('name', 'Unnamed')} ({collection.get('slugName', 'no-slug')})\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Connection failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "explore-tables"
   },
   "source": [
    "## ğŸ“Š Explore VirusSeq Tables\n",
    "\n",
    "Now let's see what tables are available in the VirusSeq collection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab_type": "code",
    "id": "list-tables"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‹ Found 3 tables in VirusSeq collection:\n",
      "\n",
      "   1. variants\n",
      "      ğŸ”— Table: collections.virusseq.variants\n",
      "      ğŸ“ Size: 42235025 rows\n",
      "      ğŸ‘† This is our target table!\n",
      "\n",
      "   2. samples\n",
      "      ğŸ”— Table: collections.virusseq.samples\n",
      "      ğŸ“ Size: 631138 rows\n",
      "\n",
      "   3. Files\n",
      "      ğŸ”— Table: collections.virusseq._files\n",
      "      ğŸ“ Size: 1888810 rows\n",
      "\n",
      "ğŸ¯ Target table found: collections.virusseq.variants\n"
     ]
    }
   ],
   "source": [
    "# List tables in the virusseq collection\n",
    "try:\n",
    "    tables = client.list_tables(\"virusseq\")\n",
    "    print(f\"ğŸ“‹ Found {len(tables)} tables in VirusSeq collection:\")\n",
    "    print()\n",
    "    \n",
    "    variants_table = None\n",
    "    for i, table in enumerate(tables, 1):\n",
    "        table_name = table.get('qualified_table_name', table.get('name', 'Unknown'))\n",
    "        display_name = table.get('display_name', table_name)\n",
    "        size = table.get('size', 'Unknown')\n",
    "        \n",
    "        print(f\"   {i}. {display_name}\")\n",
    "        print(f\"      ğŸ”— Table: {table_name}\")\n",
    "        print(f\"      ğŸ“ Size: {size} rows\")\n",
    "        \n",
    "        # Check if this is our target variants table\n",
    "        if 'variants' in table_name.lower():\n",
    "            variants_table = table\n",
    "            print(f\"      ğŸ‘† This is our target table!\")\n",
    "        \n",
    "        print()\n",
    "    \n",
    "    if variants_table:\n",
    "        print(f\"ğŸ¯ Target table found: {variants_table.get('qualified_table_name')}\")\n",
    "    else:\n",
    "        print(\"âŒ Variants table not found in the list\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Failed to list tables: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "schema"
   },
   "source": [
    "## ğŸ” Explore Variants Table Schema\n",
    "\n",
    "Let's examine the structure (schema) of the variants table to understand what data is available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab_type": "code",
    "id": "get-schema"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Variants table schema - 5 fields:\n",
      "\n",
      "    1. start_position            | string          | bigint\n",
      "    2. end_position              | string          | bigint\n",
      "    3. reference_bases           | string          | varchar\n",
      "    4. alternate_bases           | string          | varchar\n",
      "    5. sequence_accession        | string          | varchar\n",
      "\n",
      "ğŸ“Š Key fields we'll see in the data:\n",
      "   ğŸ”¹ start_position: string\n",
      "   ğŸ”¹ end_position: string\n",
      "   ğŸ”¹ reference_bases: string\n",
      "   ğŸ”¹ alternate_bases: string\n"
     ]
    }
   ],
   "source": [
    "# Get schema for the variants table\n",
    "try:\n",
    "    fields = client.get_schema_fields(\"virusseq\", \"collections.virusseq.variants\")\n",
    "    print(f\"ğŸ” Variants table schema - {len(fields)} fields:\")\n",
    "    print()\n",
    "    \n",
    "    # Show first 15 fields\n",
    "    for i, field in enumerate(fields[:15], 1):\n",
    "        field_name = field['field']\n",
    "        field_type = field['type']\n",
    "        sql_type = field.get('sql_type', '')\n",
    "        \n",
    "        print(f\"   {i:2d}. {field_name:<25} | {field_type:<15} | {sql_type}\")\n",
    "    \n",
    "    if len(fields) > 15:\n",
    "        print(f\"   ... and {len(fields) - 15} more fields\")\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Key fields we'll see in the data:\")\n",
    "    key_fields = ['pos', 'ref', 'alt', 'chrom', 'variant_id', 'sample_id']\n",
    "    for field in fields:\n",
    "        if any(key in field['field'].lower() for key in key_fields):\n",
    "            print(f\"   ğŸ”¹ {field['field']}: {field['type']}\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Failed to get schema: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "query-data"
   },
   "source": [
    "## ğŸ”¬ Query Variants Data\n",
    "\n",
    "Now let's query the variants table to get the first 10 rows of actual data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code",
    "id": "query-variants"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¬ Querying variants table...\n",
      "âš¡ This may take a moment as the query is processed asynchronously.\n",
      "\n",
      "âŒ Query failed: Unexpected response format: []\n",
      "\n",
      "ğŸ” Error details:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/54/75kj0vgs4hs2jh41xh7sbx4m0000gn/T/ipykernel_12300/2227833425.py\", line 8, in <module>\n",
      "    result = client.query(\n",
      "             ^^^^^^^^^^^^^\n",
      "  File \"/Users/mfiume/Documents/Development/omics-ai-cli/omics_ai/client.py\", line 331, in query\n",
      "    return self.query_with_polling(collection_slug, table_name, filters, limit, offset, order_by)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mfiume/Documents/Development/omics-ai-cli/omics_ai/client.py\", line 290, in query_with_polling\n",
      "    raise OmicsAIError(f\"Unexpected response format: {list(result.keys())}\")\n",
      "omics_ai.exceptions.OmicsAIError: Unexpected response format: []\n"
     ]
    }
   ],
   "source": [
    "# Query the first 10 rows from the variants table\n",
    "try:\n",
    "    print(\"ğŸ”¬ Querying variants table...\")\n",
    "    print(\"âš¡ This may take a moment as the query is processed asynchronously.\")\n",
    "    print()\n",
    "\n",
    "    print(\"Going in!\")\n",
    "    \n",
    "    # Use the standard query method from the library\n",
    "    result = client.query(\n",
    "        collection_slug=\"virusseq\", \n",
    "        table_name=\"collections.virusseq.variants\", \n",
    "        filters={},  # No filters - get all data\n",
    "        limit=10     # First 10 rows\n",
    "    )\n",
    "\n",
    "    print(\"Results:\")\n",
    "    print(result)\n",
    "    \n",
    "    # Extract the data\n",
    "    data = result.get('data', [])\n",
    "    pagination = result.get('pagination', {})\n",
    "    \n",
    "    print(f\"\\nğŸ‰ Successfully retrieved {len(data)} variant records!\")\n",
    "    \n",
    "    if pagination:\n",
    "        total = pagination.get('total', 'Unknown')\n",
    "        print(f\"ğŸ“Š Total variants in table: {total}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ğŸ“‹ FIRST 10 VARIANT RECORDS:\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Display each variant record\n",
    "    for i, variant in enumerate(data, 1):\n",
    "        print(f\"\\nğŸ”¹ Variant {i}:\")\n",
    "        \n",
    "        # Show key fields first\n",
    "        key_fields = ['pos', 'ref', 'alt', 'chrom', 'variant_id', 'sample_id']\n",
    "        for key in key_fields:\n",
    "            if key in variant:\n",
    "                print(f\"   {key:<12}: {variant[key]}\")\n",
    "        \n",
    "        # Show a few other interesting fields\n",
    "        other_fields = ['quality', 'filter', 'info', 'genotype']\n",
    "        for key in other_fields:\n",
    "            if key in variant:\n",
    "                value = variant[key]\n",
    "                if isinstance(value, str) and len(value) > 50:\n",
    "                    value = value[:50] + \"...\"\n",
    "                print(f\"   {key:<12}: {value}\")\n",
    "        \n",
    "        # Show total number of fields in this record\n",
    "        print(f\"   ğŸ“ Total fields: {len(variant)}\")\n",
    "        \n",
    "        if i < len(data):\n",
    "            print(\"   \" + \"-\"*50)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Query failed: {e}\")\n",
    "    import traceback\n",
    "    print(\"\\nğŸ” Error details:\")\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "data-analysis"
   },
   "source": [
    "## ğŸ“ˆ Convert to DataFrame\n",
    "\n",
    "Let's convert the variant data to a pandas DataFrame for easier analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab_type": "code",
    "id": "create-dataframe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ No data available to create DataFrame\n"
     ]
    }
   ],
   "source": [
    "# Convert to DataFrame if we have data\n",
    "try:\n",
    "    if 'data' in locals() and data:\n",
    "        # Create DataFrame\n",
    "        df = pd.DataFrame(data)\n",
    "        \n",
    "        print(f\"ğŸ“Š Created DataFrame with {len(df)} rows and {len(df.columns)} columns\")\n",
    "        print()\n",
    "        \n",
    "        # Show basic info\n",
    "        print(\"ğŸ” DataFrame Info:\")\n",
    "        print(f\"   Shape: {df.shape}\")\n",
    "        print(f\"   Columns: {len(df.columns)}\")\n",
    "        print()\n",
    "        \n",
    "        # Show column names\n",
    "        print(\"ğŸ“‹ Column Names:\")\n",
    "        for i, col in enumerate(df.columns[:20], 1):\n",
    "            print(f\"   {i:2d}. {col}\")\n",
    "        \n",
    "        if len(df.columns) > 20:\n",
    "            print(f\"   ... and {len(df.columns) - 20} more columns\")\n",
    "        \n",
    "        print()\n",
    "        \n",
    "        # Show first few rows with key columns\n",
    "        key_columns = []\n",
    "        for col in ['pos', 'ref', 'alt', 'chrom', 'variant_id', 'sample_id']:\n",
    "            if col in df.columns:\n",
    "                key_columns.append(col)\n",
    "        \n",
    "        if key_columns:\n",
    "            print(f\"ğŸ”¹ Key columns preview:\")\n",
    "            print(df[key_columns].head())\n",
    "        else:\n",
    "            print(f\"ğŸ”¹ First 5 columns preview:\")\n",
    "            print(df.iloc[:, :5].head())\n",
    "        \n",
    "    else:\n",
    "        print(\"âŒ No data available to create DataFrame\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Failed to create DataFrame: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "summary"
   },
   "source": [
    "## ğŸ¯ Summary\n",
    "\n",
    "**What we accomplished:**\n",
    "\n",
    "âœ… Connected to Viral AI network  \n",
    "âœ… Explored the VirusSeq collection  \n",
    "âœ… Examined the variants table schema  \n",
    "âœ… Successfully queried the first 10 variant records  \n",
    "âœ… Converted the data to a pandas DataFrame  \n",
    "\n",
    "**Next steps you could try:**\n",
    "- Query more data by increasing the `limit` parameter\n",
    "- Add filters to focus on specific chromosomes or positions\n",
    "- Analyze variant frequencies and distributions\n",
    "- Export the data for further analysis\n",
    "\n",
    "---\n",
    "\n",
    "ğŸ¦  **Viral AI Variants Explorer** - Powered by [Omics AI Explorer](https://github.com/mfiume/omics-ai-python-library)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
