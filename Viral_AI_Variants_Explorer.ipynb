{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "title"
   },
   "source": [
    "# ğŸ¦  Viral AI Variants Explorer\n",
    "\n",
    "This notebook demonstrates how to explore the **VirusSeq Variants** table on Viral AI using the Omics AI Explorer Python library.\n",
    "\n",
    "**Target Dataset**: `collections.virusseq.variants` on [viral.ai](https://viral.ai)\n",
    "\n",
    "## What we'll cover:\n",
    "- Connect to Viral AI network\n",
    "- Explore the VirusSeq collection\n",
    "- Query the variants table\n",
    "- Display the first 10 rows of variant data\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "setup"
   },
   "source": [
    "## ğŸ“¦ Setup and Installation\n",
    "\n",
    "First, let's install and import the Omics AI Explorer library:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "install-package"
   },
   "outputs": [],
   "source": "# Install the Omics AI Explorer library\n!pip install git+https://github.com/mfiume/omics-ai-python-library.git --quiet\n\n# Import required libraries\ntry:\n    from omics_ai import OmicsAIClient\n    print(\"âœ… Successfully imported OmicsAIClient!\")\nexcept ImportError:\n    print(\"âš ï¸ Package import failed, using fallback implementation...\")\n    \n    # Fallback implementation based on the working debug script\n    import requests\n    import json\n    import time\n    from typing import Dict, List, Optional, Any\n    from urllib.parse import quote\n    \n    def parse_json_lines_response(raw_text: str) -> Dict[str, Any]:\n        \"\"\"Parse JSON Lines response from Viral AI API.\"\"\"\n        if not raw_text.strip():\n            raise Exception(\"Empty response received\")\n        \n        # Split by lines and filter out empty lines\n        lines = [line.strip() for line in raw_text.strip().split('\\n') if line.strip()]\n        \n        if not lines:\n            raise Exception(\"No valid lines found in response\")\n        \n        # Parse each line as JSON\n        json_objects = []\n        for i, line in enumerate(lines):\n            try:\n                obj = json.loads(line)\n                json_objects.append(obj)\n            except json.JSONDecodeError as e:\n                if line != \"{}\":\n                    pass  # Silently ignore parsing errors\n        \n        if not json_objects:\n            raise Exception(\"No valid JSON objects found in response\")\n        \n        # Find the object with data (usually the last non-empty one)\n        for obj in reversed(json_objects):\n            if obj and 'data' in obj:\n                return obj\n        \n        # If no data object found, check for next_page_token (polling case)\n        for obj in reversed(json_objects):\n            if obj and 'next_page_token' in obj:\n                return obj\n        \n        # If we get here, we have only empty objects {} or unexpected format\n        if all(not obj for obj in json_objects):\n            return {\"next_page_token\": \"empty_response_poll\"}\n        \n        # Return the last non-empty object\n        non_empty_objects = [obj for obj in json_objects if obj]\n        if non_empty_objects:\n            return non_empty_objects[-1]\n        \n        raise Exception(f\"No data or next_page_token found. Objects: {json_objects}\")\n    \n    class OmicsAIClient:\n        \"\"\"Simplified Omics AI Explorer client for Viral AI.\"\"\"\n        \n        def __init__(self, network: str = \"viral.ai\"):\n            if not network.startswith(('http://', 'https://')):\n                network = f\"https://{network}\"\n            self.network = network.rstrip('/')\n            self.session = requests.Session()\n            self.session.headers.update({\n                'User-Agent': 'viral-ai-explorer/1.0',\n                'Accept': 'application/json',\n                'Content-Type': 'application/json'\n            })\n        \n        def _make_request(self, method: str, endpoint: str, **kwargs):\n            url = f\"{self.network}{endpoint}\"\n            response = self.session.request(method, url, **kwargs)\n            response.raise_for_status()\n            return response\n        \n        def list_collections(self) -> List[Dict[str, Any]]:\n            response = self._make_request('GET', '/api/collections')\n            return response.json()\n        \n        def list_tables(self, collection_slug: str) -> List[Dict[str, Any]]:\n            endpoint = f\"/api/collections/{quote(collection_slug)}/tables\"\n            response = self._make_request('GET', endpoint)\n            return response.json()\n        \n        def get_schema_fields(self, collection_slug: str, table_name: str) -> List[Dict[str, str]]:\n            endpoint = f\"/api/collection/{quote(collection_slug)}/data-connect/table/{quote(table_name)}/info\"\n            response = self._make_request('GET', endpoint)\n            schema = response.json()\n            \n            data_model = schema.get('data_model', {}).get('properties', {})\n            fields = []\n            for field_name, field_spec in data_model.items():\n                field_type = field_spec.get('type', '')\n                if isinstance(field_type, list):\n                    field_type = ', '.join(field_type)\n                if field_type == 'array' and 'items' in field_spec:\n                    item_type = field_spec['items'].get('type', '')\n                    if isinstance(item_type, list):\n                        item_type = ', '.join(item_type)\n                    field_type = f\"array<{item_type}>\"\n                \n                fields.append({\n                    'field': field_name,\n                    'type': field_type,\n                    'sql_type': field_spec.get('sqlType', '')\n                })\n            return fields\n        \n        def query(self, collection_slug: str, table_name: str, \n                 filters=None, limit: int = 100, offset: int = 0,\n                 max_polls: int = 10, poll_interval: float = 2.0) -> Dict[str, Any]:\n            \"\"\"Query with auto-polling for async results.\"\"\"\n            if filters is None:\n                filters = {}\n                \n            payload = {\n                \"tableName\": table_name,\n                \"filters\": filters,\n                \"pagination\": {\"limit\": limit, \"offset\": offset}\n            }\n            \n            endpoint = f\"/api/collections/{quote(collection_slug)}/tables/{quote(table_name)}/filter\"\n            \n            for poll_count in range(max_polls):\n                response = self._make_request('POST', endpoint, json=payload)\n                \n                # Parse response\n                try:\n                    result = parse_json_lines_response(response.text)\n                except Exception as e:\n                    raise Exception(f\"Failed to parse response: {e}\")\n                \n                # Check if we have data or need to poll\n                if 'data' in result and isinstance(result['data'], list):\n                    return result\n                elif 'next_page_token' in result or result.get('next_page_token') == 'empty_response_poll':\n                    if result.get('next_page_token') != 'empty_response_poll':\n                        payload['next_page_token'] = result['next_page_token']\n                    time.sleep(poll_interval)\n                else:\n                    return result  # Return whatever we got\n            \n            raise Exception(f\"Query timed out after {max_polls} polls\")\n    \n    print(\"âœ… Using fallback implementation with working JSON Lines parser!\")\n\n# Import data analysis libraries\nimport pandas as pd\nfrom datetime import datetime\n\nprint(\"\\nğŸ¦  Viral AI Variants Explorer Ready!\")\nprint(f\"ğŸ“… Started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "connect"
   },
   "source": [
    "## ğŸ”— Connect to Viral AI\n",
    "\n",
    "Let's connect to the Viral AI network and explore what's available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab_type": "code",
    "id": "connect-viral-ai"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”— Connected to Viral AI!\n",
      "ğŸŒ Network: https://viral.ai\n",
      "âœ… Connection successful! Found 18 collections.\n",
      "\n",
      "ğŸ¯ Found VirusSeq collection:\n",
      "   ğŸ“‹ Name: VirusSeq SARS-CoV-2 Genome Sequences\n",
      "   ğŸ”— Slug: virusseq\n",
      "   ğŸ“ Description: <p>The&nbsp;mission&nbsp;of&nbsp;Canadian&nbsp;COVID&nbsp;Genomics&nbsp;Network&nbsp;(<a href=\"https...\n"
     ]
    }
   ],
   "source": [
    "# Create client for Viral AI\n",
    "client = OmicsAIClient(\"viral.ai\")\n",
    "\n",
    "print(\"ğŸ”— Connected to Viral AI!\")\n",
    "print(f\"ğŸŒ Network: {client.network}\")\n",
    "\n",
    "# Test basic connection\n",
    "try:\n",
    "    collections = client.list_collections()\n",
    "    print(f\"âœ… Connection successful! Found {len(collections)} collections.\")\n",
    "    \n",
    "    # Look for the virusseq collection\n",
    "    virusseq_collection = None\n",
    "    for collection in collections:\n",
    "        if collection.get('slugName') == 'virusseq':\n",
    "            virusseq_collection = collection\n",
    "            break\n",
    "    \n",
    "    if virusseq_collection:\n",
    "        print(f\"\\nğŸ¯ Found VirusSeq collection:\")\n",
    "        print(f\"   ğŸ“‹ Name: {virusseq_collection.get('name', 'N/A')}\")\n",
    "        print(f\"   ğŸ”— Slug: {virusseq_collection.get('slugName', 'N/A')}\")\n",
    "        print(f\"   ğŸ“ Description: {virusseq_collection.get('description', 'N/A')[:100]}...\")\n",
    "    else:\n",
    "        print(\"âŒ VirusSeq collection not found\")\n",
    "        print(\"Available collections:\")\n",
    "        for collection in collections[:5]:\n",
    "            print(f\"   - {collection.get('name', 'Unnamed')} ({collection.get('slugName', 'no-slug')})\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Connection failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "explore-tables"
   },
   "source": [
    "## ğŸ“Š Explore VirusSeq Tables\n",
    "\n",
    "Now let's see what tables are available in the VirusSeq collection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab_type": "code",
    "id": "list-tables"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‹ Found 3 tables in VirusSeq collection:\n",
      "\n",
      "   1. variants\n",
      "      ğŸ”— Table: collections.virusseq.variants\n",
      "      ğŸ“ Size: 42235025 rows\n",
      "      ğŸ‘† This is our target table!\n",
      "\n",
      "   2. samples\n",
      "      ğŸ”— Table: collections.virusseq.samples\n",
      "      ğŸ“ Size: 631138 rows\n",
      "\n",
      "   3. Files\n",
      "      ğŸ”— Table: collections.virusseq._files\n",
      "      ğŸ“ Size: 1888810 rows\n",
      "\n",
      "ğŸ¯ Target table found: collections.virusseq.variants\n"
     ]
    }
   ],
   "source": [
    "# List tables in the virusseq collection\n",
    "try:\n",
    "    tables = client.list_tables(\"virusseq\")\n",
    "    print(f\"ğŸ“‹ Found {len(tables)} tables in VirusSeq collection:\")\n",
    "    print()\n",
    "    \n",
    "    variants_table = None\n",
    "    for i, table in enumerate(tables, 1):\n",
    "        table_name = table.get('qualified_table_name', table.get('name', 'Unknown'))\n",
    "        display_name = table.get('display_name', table_name)\n",
    "        size = table.get('size', 'Unknown')\n",
    "        \n",
    "        print(f\"   {i}. {display_name}\")\n",
    "        print(f\"      ğŸ”— Table: {table_name}\")\n",
    "        print(f\"      ğŸ“ Size: {size} rows\")\n",
    "        \n",
    "        # Check if this is our target variants table\n",
    "        if 'variants' in table_name.lower():\n",
    "            variants_table = table\n",
    "            print(f\"      ğŸ‘† This is our target table!\")\n",
    "        \n",
    "        print()\n",
    "    \n",
    "    if variants_table:\n",
    "        print(f\"ğŸ¯ Target table found: {variants_table.get('qualified_table_name')}\")\n",
    "    else:\n",
    "        print(\"âŒ Variants table not found in the list\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Failed to list tables: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "schema"
   },
   "source": [
    "## ğŸ” Explore Variants Table Schema\n",
    "\n",
    "Let's examine the structure (schema) of the variants table to understand what data is available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab_type": "code",
    "id": "get-schema"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Variants table schema - 5 fields:\n",
      "\n",
      "    1. start_position            | string          | bigint\n",
      "    2. end_position              | string          | bigint\n",
      "    3. reference_bases           | string          | varchar\n",
      "    4. alternate_bases           | string          | varchar\n",
      "    5. sequence_accession        | string          | varchar\n",
      "\n",
      "ğŸ“Š Key fields we'll see in the data:\n",
      "   ğŸ”¹ start_position: string\n",
      "   ğŸ”¹ end_position: string\n",
      "   ğŸ”¹ reference_bases: string\n",
      "   ğŸ”¹ alternate_bases: string\n"
     ]
    }
   ],
   "source": [
    "# Get schema for the variants table\n",
    "try:\n",
    "    fields = client.get_schema_fields(\"virusseq\", \"collections.virusseq.variants\")\n",
    "    print(f\"ğŸ” Variants table schema - {len(fields)} fields:\")\n",
    "    print()\n",
    "    \n",
    "    # Show first 15 fields\n",
    "    for i, field in enumerate(fields[:15], 1):\n",
    "        field_name = field['field']\n",
    "        field_type = field['type']\n",
    "        sql_type = field.get('sql_type', '')\n",
    "        \n",
    "        print(f\"   {i:2d}. {field_name:<25} | {field_type:<15} | {sql_type}\")\n",
    "    \n",
    "    if len(fields) > 15:\n",
    "        print(f\"   ... and {len(fields) - 15} more fields\")\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Key fields we'll see in the data:\")\n",
    "    key_fields = ['pos', 'ref', 'alt', 'chrom', 'variant_id', 'sample_id']\n",
    "    for field in fields:\n",
    "        if any(key in field['field'].lower() for key in key_fields):\n",
    "            print(f\"   ğŸ”¹ {field['field']}: {field['type']}\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Failed to get schema: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "query-data"
   },
   "source": [
    "## ğŸ”¬ Query Variants Data\n",
    "\n",
    "Now let's query the variants table to get the first 10 rows of actual data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code",
    "id": "query-variants"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¬ Querying variants table...\n",
      "âš¡ This may take a moment as the query is processed asynchronously.\n",
      "\n",
      "Going in!\n",
      "Results:\n",
      "{'data': [{'start_position': 10455, 'end_position': 10456, 'reference_bases': 'C', 'alternate_bases': 'T', 'sequence_accession': 'hCoV-19/Canada/AB-ABPHL-102772/2023'}, {'start_position': 10457, 'end_position': 10458, 'reference_bases': 'C', 'alternate_bases': 'T', 'sequence_accession': 'hCoV-19/Canada/BC-BCCDC-101979/2021'}, {'start_position': 10457, 'end_position': 10458, 'reference_bases': 'C', 'alternate_bases': 'T', 'sequence_accession': 'hCoV-19/Canada/BC-BCCDC-92384/2021'}, {'start_position': 10457, 'end_position': 10458, 'reference_bases': 'C', 'alternate_bases': 'T', 'sequence_accession': 'hCoV-19/Canada/BC-BCCDC-75322/2021'}, {'start_position': 10457, 'end_position': 10458, 'reference_bases': 'C', 'alternate_bases': 'T', 'sequence_accession': 'hCoV-19/Canada/BC-BCCDC-78406/2021'}, {'start_position': 10457, 'end_position': 10458, 'reference_bases': 'C', 'alternate_bases': 'T', 'sequence_accession': 'hCoV-19/Canada/BC-BCCDC-93803/2021'}, {'start_position': 10457, 'end_position': 10458, 'reference_bases': 'C', 'alternate_bases': 'T', 'sequence_accession': 'hCoV-19/Canada/BC-BCCDC-113415/2021'}, {'start_position': 10473, 'end_position': 10474, 'reference_bases': 'C', 'alternate_bases': 'T', 'sequence_accession': 'hCoV-19/Canada/MB-CPL-629515/2023'}, {'start_position': 10473, 'end_position': 10474, 'reference_bases': 'C', 'alternate_bases': 'T', 'sequence_accession': 'hCoV-19/Canada/BC-BCCDC-174387/2021'}, {'start_position': 10473, 'end_position': 10474, 'reference_bases': 'C', 'alternate_bases': 'T', 'sequence_accession': 'hCoV-19/Canada/MB-CPL-634595/2023'}], 'pagination': {'next_page_url': None, 'previous_page_url': None}, 'data_model': {'description': 'Automatically generated schema', '$schema': 'http://json-schema.org/draft-07/schema#', 'properties': {'start_position': {'format': 'bigint', 'type': 'int', '$comment': 'bigint'}, 'end_position': {'format': 'bigint', 'type': 'int', '$comment': 'bigint'}, 'reference_bases': {'format': 'varchar', 'type': 'string', '$comment': 'varchar'}, 'alternate_bases': {'format': 'varchar', 'type': 'string', '$comment': 'varchar'}, 'sequence_accession': {'format': 'varchar', 'type': 'string', '$comment': 'varchar'}}}}\n",
      "\n",
      "ğŸ‰ Successfully retrieved 10 variant records!\n",
      "ğŸ“Š Total variants in table: Unknown\n",
      "\n",
      "================================================================================\n",
      "ğŸ“‹ FIRST 10 VARIANT RECORDS:\n",
      "================================================================================\n",
      "\n",
      "ğŸ”¹ Variant 1:\n",
      "   ğŸ“ Total fields: 5\n",
      "   --------------------------------------------------\n",
      "\n",
      "ğŸ”¹ Variant 2:\n",
      "   ğŸ“ Total fields: 5\n",
      "   --------------------------------------------------\n",
      "\n",
      "ğŸ”¹ Variant 3:\n",
      "   ğŸ“ Total fields: 5\n",
      "   --------------------------------------------------\n",
      "\n",
      "ğŸ”¹ Variant 4:\n",
      "   ğŸ“ Total fields: 5\n",
      "   --------------------------------------------------\n",
      "\n",
      "ğŸ”¹ Variant 5:\n",
      "   ğŸ“ Total fields: 5\n",
      "   --------------------------------------------------\n",
      "\n",
      "ğŸ”¹ Variant 6:\n",
      "   ğŸ“ Total fields: 5\n",
      "   --------------------------------------------------\n",
      "\n",
      "ğŸ”¹ Variant 7:\n",
      "   ğŸ“ Total fields: 5\n",
      "   --------------------------------------------------\n",
      "\n",
      "ğŸ”¹ Variant 8:\n",
      "   ğŸ“ Total fields: 5\n",
      "   --------------------------------------------------\n",
      "\n",
      "ğŸ”¹ Variant 9:\n",
      "   ğŸ“ Total fields: 5\n",
      "   --------------------------------------------------\n",
      "\n",
      "ğŸ”¹ Variant 10:\n",
      "   ğŸ“ Total fields: 5\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Query the first 10 rows from the variants table\n",
    "try:\n",
    "    print(\"ğŸ”¬ Querying variants table...\")\n",
    "    print(\"âš¡ This may take a moment as the query is processed asynchronously.\")\n",
    "    print()\n",
    "\n",
    "    # Use the standard query method from the library\n",
    "    result = client.query(\n",
    "        collection_slug=\"virusseq\", \n",
    "        table_name=\"collections.virusseq.variants\", \n",
    "        filters={},  # No filters - get all data\n",
    "        limit=10     # First 10 rows\n",
    "    )\n",
    "\n",
    "    # Extract the data\n",
    "    data = result.get('data', [])\n",
    "    pagination = result.get('pagination', {})\n",
    "    \n",
    "    print(f\"\\nğŸ‰ Successfully retrieved {len(data)} variant records!\")\n",
    "    \n",
    "    if pagination:\n",
    "        total = pagination.get('total', 'Unknown')\n",
    "        print(f\"ğŸ“Š Total variants in table: {total}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ğŸ“‹ FIRST 10 VARIANT RECORDS:\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Display each variant record\n",
    "    for i, variant in enumerate(data, 1):\n",
    "        print(f\"\\nğŸ”¹ Variant {i}:\")\n",
    "        \n",
    "        # Show key fields first\n",
    "        key_fields = ['pos', 'ref', 'alt', 'chrom', 'variant_id', 'sample_id']\n",
    "        for key in key_fields:\n",
    "            if key in variant:\n",
    "                print(f\"   {key:<12}: {variant[key]}\")\n",
    "        \n",
    "        # Show a few other interesting fields\n",
    "        other_fields = ['quality', 'filter', 'info', 'genotype']\n",
    "        for key in other_fields:\n",
    "            if key in variant:\n",
    "                value = variant[key]\n",
    "                if isinstance(value, str) and len(value) > 50:\n",
    "                    value = value[:50] + \"...\"\n",
    "                print(f\"   {key:<12}: {value}\")\n",
    "        \n",
    "        # Show total number of fields in this record\n",
    "        print(f\"   ğŸ“ Total fields: {len(variant)}\")\n",
    "        \n",
    "        if i < len(data):\n",
    "            print(\"   \" + \"-\"*50)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Query failed: {e}\")\n",
    "    import traceback\n",
    "    print(\"\\nğŸ” Error details:\")\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "data-analysis"
   },
   "source": [
    "## ğŸ“ˆ Convert to DataFrame\n",
    "\n",
    "Let's convert the variant data to a pandas DataFrame for easier analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab_type": "code",
    "id": "create-dataframe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Created DataFrame with 10 rows and 5 columns\n",
      "\n",
      "ğŸ” DataFrame Info:\n",
      "   Shape: (10, 5)\n",
      "   Columns: 5\n",
      "\n",
      "ğŸ“‹ Column Names:\n",
      "    1. start_position\n",
      "    2. end_position\n",
      "    3. reference_bases\n",
      "    4. alternate_bases\n",
      "    5. sequence_accession\n",
      "\n",
      "ğŸ”¹ First 5 columns preview:\n",
      "   start_position  end_position reference_bases alternate_bases  \\\n",
      "0           10455         10456               C               T   \n",
      "1           10457         10458               C               T   \n",
      "2           10457         10458               C               T   \n",
      "3           10457         10458               C               T   \n",
      "4           10457         10458               C               T   \n",
      "\n",
      "                    sequence_accession  \n",
      "0  hCoV-19/Canada/AB-ABPHL-102772/2023  \n",
      "1  hCoV-19/Canada/BC-BCCDC-101979/2021  \n",
      "2   hCoV-19/Canada/BC-BCCDC-92384/2021  \n",
      "3   hCoV-19/Canada/BC-BCCDC-75322/2021  \n",
      "4   hCoV-19/Canada/BC-BCCDC-78406/2021  \n"
     ]
    }
   ],
   "source": [
    "# Convert to DataFrame if we have data\n",
    "try:\n",
    "    if 'data' in locals() and data:\n",
    "        # Create DataFrame\n",
    "        df = pd.DataFrame(data)\n",
    "        \n",
    "        print(f\"ğŸ“Š Created DataFrame with {len(df)} rows and {len(df.columns)} columns\")\n",
    "        print()\n",
    "        \n",
    "        # Show basic info\n",
    "        print(\"ğŸ” DataFrame Info:\")\n",
    "        print(f\"   Shape: {df.shape}\")\n",
    "        print(f\"   Columns: {len(df.columns)}\")\n",
    "        print()\n",
    "        \n",
    "        # Show column names\n",
    "        print(\"ğŸ“‹ Column Names:\")\n",
    "        for i, col in enumerate(df.columns[:20], 1):\n",
    "            print(f\"   {i:2d}. {col}\")\n",
    "        \n",
    "        if len(df.columns) > 20:\n",
    "            print(f\"   ... and {len(df.columns) - 20} more columns\")\n",
    "        \n",
    "        print()\n",
    "        \n",
    "        # Show first few rows with key columns\n",
    "        key_columns = []\n",
    "        for col in ['pos', 'ref', 'alt', 'chrom', 'variant_id', 'sample_id']:\n",
    "            if col in df.columns:\n",
    "                key_columns.append(col)\n",
    "        \n",
    "        if key_columns:\n",
    "            print(f\"ğŸ”¹ Key columns preview:\")\n",
    "            print(df[key_columns].head())\n",
    "        else:\n",
    "            print(f\"ğŸ”¹ First 5 columns preview:\")\n",
    "            print(df.iloc[:, :5].head())\n",
    "        \n",
    "    else:\n",
    "        print(\"âŒ No data available to create DataFrame\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Failed to create DataFrame: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "summary"
   },
   "source": [
    "## ğŸ¯ Summary\n",
    "\n",
    "**What we accomplished:**\n",
    "\n",
    "âœ… Connected to Viral AI network  \n",
    "âœ… Explored the VirusSeq collection  \n",
    "âœ… Examined the variants table schema  \n",
    "âœ… Successfully queried the first 10 variant records  \n",
    "âœ… Converted the data to a pandas DataFrame  \n",
    "\n",
    "**Next steps you could try:**\n",
    "- Query more data by increasing the `limit` parameter\n",
    "- Add filters to focus on specific chromosomes or positions\n",
    "- Analyze variant frequencies and distributions\n",
    "- Export the data for further analysis\n",
    "\n",
    "---\n",
    "\n",
    "ğŸ¦  **Viral AI Variants Explorer** - Powered by [Omics AI Explorer](https://github.com/mfiume/omics-ai-python-library)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}