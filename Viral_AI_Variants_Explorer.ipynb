{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "title"
   },
   "source": [
    "# ü¶† Viral AI Variants Explorer\n",
    "\n",
    "This notebook demonstrates how to explore the **VirusSeq Variants** table on Viral AI using the Omics AI Explorer Python library.\n",
    "\n",
    "**Target Dataset**: `collections.virusseq.variants` on [viral.ai](https://viral.ai)\n",
    "\n",
    "## What we'll cover:\n",
    "- Connect to Viral AI network\n",
    "- Explore the VirusSeq collection\n",
    "- Query the variants table\n",
    "- Display the first 10 rows of variant data\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "setup"
   },
   "source": [
    "## üì¶ Setup and Installation\n",
    "\n",
    "First, let's install and import the Omics AI Explorer library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab_type": "code",
    "id": "install-package"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: pip\n",
      "‚úÖ Successfully imported OmicsAIClient!\n",
      "\n",
      "ü¶† Viral AI Variants Explorer Ready!\n",
      "üìÖ Started at: 2025-06-11 09:34:59\n"
     ]
    }
   ],
   "source": [
    "# Install the Omics AI Explorer library\n",
    "!pip install git+https://github.com/mfiume/omics-ai-python-library.git --quiet\n",
    "\n",
    "# Import required libraries\n",
    "try:\n",
    "    from omics_ai import OmicsAIClient\n",
    "    print(\"‚úÖ Successfully imported OmicsAIClient!\")\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è Package import failed, using fallback implementation...\")\n",
    "    \n",
    "    # Fallback implementation based on the working debug script\n",
    "    import requests\n",
    "    import json\n",
    "    import time\n",
    "    from typing import Dict, List, Optional, Any\n",
    "    from urllib.parse import quote\n",
    "    \n",
    "    def parse_json_lines_response(raw_text: str, debug: bool = False) -> Dict[str, Any]:\n",
    "        \"\"\"Parse JSON Lines response from Viral AI API.\"\"\"\n",
    "        if debug:\n",
    "            print(f\"üîç Debug: Raw response length: {len(raw_text)}\")\n",
    "            print(f\"üîç Debug: First 200 chars: {raw_text[:200]}\")\n",
    "            \n",
    "        if not raw_text.strip():\n",
    "            raise Exception(\"Empty response received\")\n",
    "        \n",
    "        # Split by lines and filter out empty lines\n",
    "        lines = [line.strip() for line in raw_text.strip().split('\\n') if line.strip()]\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"üîç Debug: Found {len(lines)} non-empty lines\")\n",
    "            for i, line in enumerate(lines[:3]):\n",
    "                print(f\"üîç Debug: Line {i+1}: {line[:100]}...\")\n",
    "        \n",
    "        if not lines:\n",
    "            raise Exception(\"No valid lines found in response\")\n",
    "        \n",
    "        # Parse each line as JSON\n",
    "        json_objects = []\n",
    "        for i, line in enumerate(lines):\n",
    "            try:\n",
    "                obj = json.loads(line)\n",
    "                json_objects.append(obj)\n",
    "                if debug:\n",
    "                    keys = list(obj.keys()) if obj else []\n",
    "                    print(f\"üîç Debug: Parsed line {i+1}: keys={keys}\")\n",
    "                    if obj and 'data' in obj:\n",
    "                        print(f\"üîç Debug: Line {i+1} has data array with {len(obj['data'])} items\")\n",
    "            except json.JSONDecodeError as e:\n",
    "                if debug:\n",
    "                    print(f\"üîç Debug: Failed to parse line {i+1}: {e}\")\n",
    "                if line != \"{}\":\n",
    "                    print(f\"‚ö†Ô∏è Failed to parse line {i+1}: {line[:100]}... - {e}\")\n",
    "        \n",
    "        if not json_objects:\n",
    "            raise Exception(\"No valid JSON objects found in response\")\n",
    "        \n",
    "        # Find the object with data (usually the last non-empty one)\n",
    "        for obj in reversed(json_objects):\n",
    "            if obj and 'data' in obj:\n",
    "                if debug:\n",
    "                    print(f\"üîç Debug: Found data object with {len(obj['data'])} rows\")\n",
    "                return obj\n",
    "        \n",
    "        # If no data object found, check for next_page_token (polling case)\n",
    "        for obj in reversed(json_objects):\n",
    "            if obj and 'next_page_token' in obj:\n",
    "                if debug:\n",
    "                    print(f\"üîç Debug: Found next_page_token: {obj['next_page_token'][:50]}...\")\n",
    "                return obj\n",
    "        \n",
    "        # If we get here, we have only empty objects {} or unexpected format\n",
    "        if all(not obj for obj in json_objects):\n",
    "            if debug:\n",
    "                print(\"üîç Debug: All objects are empty, treating as polling case\")\n",
    "            return {\"next_page_token\": \"empty_response_poll\"}\n",
    "        \n",
    "        # Return the last non-empty object\n",
    "        non_empty_objects = [obj for obj in json_objects if obj]\n",
    "        if non_empty_objects:\n",
    "            result = non_empty_objects[-1]\n",
    "            if debug:\n",
    "                print(f\"üîç Debug: Returning last non-empty object with keys: {list(result.keys())}\")\n",
    "            return result\n",
    "        \n",
    "        raise Exception(f\"No data or next_page_token found. Objects: {json_objects}\")\n",
    "    \n",
    "    class OmicsAIClient:\n",
    "        \"\"\"Simplified Omics AI Explorer client for Viral AI.\"\"\"\n",
    "        \n",
    "        def __init__(self, network: str = \"viral.ai\"):\n",
    "            if not network.startswith(('http://', 'https://')):\n",
    "                network = f\"https://{network}\"\n",
    "            self.network = network.rstrip('/')\n",
    "            self.session = requests.Session()\n",
    "            self.session.headers.update({\n",
    "                'User-Agent': 'viral-ai-explorer/1.0',\n",
    "                'Accept': 'application/json',\n",
    "                'Content-Type': 'application/json'\n",
    "            })\n",
    "        \n",
    "        def _make_request(self, method: str, endpoint: str, **kwargs):\n",
    "            url = f\"{self.network}{endpoint}\"\n",
    "            response = self.session.request(method, url, **kwargs)\n",
    "            response.raise_for_status()\n",
    "            return response\n",
    "        \n",
    "        def list_collections(self) -> List[Dict[str, Any]]:\n",
    "            response = self._make_request('GET', '/api/collections')\n",
    "            return response.json()\n",
    "        \n",
    "        def list_tables(self, collection_slug: str) -> List[Dict[str, Any]]:\n",
    "            endpoint = f\"/api/collections/{quote(collection_slug)}/tables\"\n",
    "            response = self._make_request('GET', endpoint)\n",
    "            return response.json()\n",
    "        \n",
    "        def get_schema_fields(self, collection_slug: str, table_name: str) -> List[Dict[str, str]]:\n",
    "            endpoint = f\"/api/collection/{quote(collection_slug)}/data-connect/table/{quote(table_name)}/info\"\n",
    "            response = self._make_request('GET', endpoint)\n",
    "            schema = response.json()\n",
    "            \n",
    "            data_model = schema.get('data_model', {}).get('properties', {})\n",
    "            fields = []\n",
    "            for field_name, field_spec in data_model.items():\n",
    "                field_type = field_spec.get('type', '')\n",
    "                if isinstance(field_type, list):\n",
    "                    field_type = ', '.join(field_type)\n",
    "                if field_type == 'array' and 'items' in field_spec:\n",
    "                    item_type = field_spec['items'].get('type', '')\n",
    "                    if isinstance(item_type, list):\n",
    "                        item_type = ', '.join(item_type)\n",
    "                    field_type = f\"array<{item_type}>\"\n",
    "                \n",
    "                fields.append({\n",
    "                    'field': field_name,\n",
    "                    'type': field_type,\n",
    "                    'sql_type': field_spec.get('sqlType', '')\n",
    "                })\n",
    "            return fields\n",
    "        \n",
    "        def query_with_polling(self, collection_slug: str, table_name: str, \n",
    "                             filters=None, limit: int = 100, offset: int = 0,\n",
    "                             max_polls: int = 10, poll_interval: float = 2.0, \n",
    "                             debug: bool = False) -> Dict[str, Any]:\n",
    "            \"\"\"Query with polling for async results.\"\"\"\n",
    "            if filters is None:\n",
    "                filters = {}\n",
    "                \n",
    "            payload = {\n",
    "                \"tableName\": table_name,\n",
    "                \"filters\": filters,\n",
    "                \"pagination\": {\"limit\": limit, \"offset\": offset}\n",
    "            }\n",
    "            \n",
    "            endpoint = f\"/api/collections/{quote(collection_slug)}/tables/{quote(table_name)}/filter\"\n",
    "            \n",
    "            if debug:\n",
    "                print(f\"üîç Debug: Endpoint: {self.network}{endpoint}\")\n",
    "                print(f\"üîç Debug: Payload: {json.dumps(payload, indent=2)}\")\n",
    "            \n",
    "            print(f\"üîÑ Starting async query (max {max_polls} polls, {poll_interval}s interval)...\")\n",
    "            \n",
    "            for poll_count in range(max_polls):\n",
    "                response = self._make_request('POST', endpoint, json=payload)\n",
    "                \n",
    "                if debug:\n",
    "                    print(f\"üîç Debug: Poll {poll_count + 1} response status: {response.status_code}\")\n",
    "                \n",
    "                # Parse response\n",
    "                try:\n",
    "                    result = parse_json_lines_response(response.text, debug=debug)\n",
    "                except Exception as e:\n",
    "                    raise Exception(f\"Failed to parse response: {e}\")\n",
    "                \n",
    "                # Check if we have data or need to poll\n",
    "                if 'data' in result and isinstance(result['data'], list):\n",
    "                    print(f\"‚úÖ Data ready after {poll_count + 1} poll(s)!\")\n",
    "                    return result\n",
    "                elif 'next_page_token' in result or result.get('next_page_token') == 'empty_response_poll':\n",
    "                    print(f\"   Poll {poll_count + 1}/{max_polls}: Data not ready, polling again in {poll_interval}s...\")\n",
    "                    if result.get('next_page_token') != 'empty_response_poll':\n",
    "                        payload['next_page_token'] = result['next_page_token']\n",
    "                    time.sleep(poll_interval)\n",
    "                else:\n",
    "                    return result  # Return whatever we got\n",
    "            \n",
    "            raise Exception(f\"Query timed out after {max_polls} polls\")\n",
    "        \n",
    "        def query(self, collection_slug: str, table_name: str, filters=None, limit: int = 100, **kwargs) -> Dict[str, Any]:\n",
    "            \"\"\"Query with auto-polling.\"\"\"\n",
    "            return self.query_with_polling(collection_slug, table_name, filters=filters, limit=limit)\n",
    "    \n",
    "    print(\"‚úÖ Using fallback implementation with working JSON Lines parser!\")\n",
    "\n",
    "# Import data analysis libraries\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"\\nü¶† Viral AI Variants Explorer Ready!\")\n",
    "print(f\"üìÖ Started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "connect"
   },
   "source": [
    "## üîó Connect to Viral AI\n",
    "\n",
    "Let's connect to the Viral AI network and explore what's available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab_type": "code",
    "id": "connect-viral-ai"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîó Connected to Viral AI!\n",
      "üåê Network: https://viral.ai\n",
      "‚úÖ Connection successful! Found 18 collections.\n",
      "\n",
      "üéØ Found VirusSeq collection:\n",
      "   üìã Name: VirusSeq SARS-CoV-2 Genome Sequences\n",
      "   üîó Slug: virusseq\n",
      "   üìù Description: <p>The&nbsp;mission&nbsp;of&nbsp;Canadian&nbsp;COVID&nbsp;Genomics&nbsp;Network&nbsp;(<a href=\"https...\n"
     ]
    }
   ],
   "source": [
    "# Create client for Viral AI\n",
    "client = OmicsAIClient(\"viral.ai\")\n",
    "\n",
    "print(\"üîó Connected to Viral AI!\")\n",
    "print(f\"üåê Network: {client.network}\")\n",
    "\n",
    "# Test basic connection\n",
    "try:\n",
    "    collections = client.list_collections()\n",
    "    print(f\"‚úÖ Connection successful! Found {len(collections)} collections.\")\n",
    "    \n",
    "    # Look for the virusseq collection\n",
    "    virusseq_collection = None\n",
    "    for collection in collections:\n",
    "        if collection.get('slugName') == 'virusseq':\n",
    "            virusseq_collection = collection\n",
    "            break\n",
    "    \n",
    "    if virusseq_collection:\n",
    "        print(f\"\\nüéØ Found VirusSeq collection:\")\n",
    "        print(f\"   üìã Name: {virusseq_collection.get('name', 'N/A')}\")\n",
    "        print(f\"   üîó Slug: {virusseq_collection.get('slugName', 'N/A')}\")\n",
    "        print(f\"   üìù Description: {virusseq_collection.get('description', 'N/A')[:100]}...\")\n",
    "    else:\n",
    "        print(\"‚ùå VirusSeq collection not found\")\n",
    "        print(\"Available collections:\")\n",
    "        for collection in collections[:5]:\n",
    "            print(f\"   - {collection.get('name', 'Unnamed')} ({collection.get('slugName', 'no-slug')})\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Connection failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "explore-tables"
   },
   "source": [
    "## üìä Explore VirusSeq Tables\n",
    "\n",
    "Now let's see what tables are available in the VirusSeq collection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab_type": "code",
    "id": "list-tables"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Found 3 tables in VirusSeq collection:\n",
      "\n",
      "   1. variants\n",
      "      üîó Table: collections.virusseq.variants\n",
      "      üìè Size: 42235025 rows\n",
      "      üëÜ This is our target table!\n",
      "\n",
      "   2. samples\n",
      "      üîó Table: collections.virusseq.samples\n",
      "      üìè Size: 631138 rows\n",
      "\n",
      "   3. Files\n",
      "      üîó Table: collections.virusseq._files\n",
      "      üìè Size: 1888810 rows\n",
      "\n",
      "üéØ Target table found: collections.virusseq.variants\n"
     ]
    }
   ],
   "source": [
    "# List tables in the virusseq collection\n",
    "try:\n",
    "    tables = client.list_tables(\"virusseq\")\n",
    "    print(f\"üìã Found {len(tables)} tables in VirusSeq collection:\")\n",
    "    print()\n",
    "    \n",
    "    variants_table = None\n",
    "    for i, table in enumerate(tables, 1):\n",
    "        table_name = table.get('qualified_table_name', table.get('name', 'Unknown'))\n",
    "        display_name = table.get('display_name', table_name)\n",
    "        size = table.get('size', 'Unknown')\n",
    "        \n",
    "        print(f\"   {i}. {display_name}\")\n",
    "        print(f\"      üîó Table: {table_name}\")\n",
    "        print(f\"      üìè Size: {size} rows\")\n",
    "        \n",
    "        # Check if this is our target variants table\n",
    "        if 'variants' in table_name.lower():\n",
    "            variants_table = table\n",
    "            print(f\"      üëÜ This is our target table!\")\n",
    "        \n",
    "        print()\n",
    "    \n",
    "    if variants_table:\n",
    "        print(f\"üéØ Target table found: {variants_table.get('qualified_table_name')}\")\n",
    "    else:\n",
    "        print(\"‚ùå Variants table not found in the list\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to list tables: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "schema"
   },
   "source": [
    "## üîç Explore Variants Table Schema\n",
    "\n",
    "Let's examine the structure (schema) of the variants table to understand what data is available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab_type": "code",
    "id": "get-schema"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Variants table schema - 5 fields:\n",
      "\n",
      "    1. start_position            | string          | bigint\n",
      "    2. end_position              | string          | bigint\n",
      "    3. reference_bases           | string          | varchar\n",
      "    4. alternate_bases           | string          | varchar\n",
      "    5. sequence_accession        | string          | varchar\n",
      "\n",
      "üìä Key fields we'll see in the data:\n",
      "   üîπ start_position: string\n",
      "   üîπ end_position: string\n",
      "   üîπ reference_bases: string\n",
      "   üîπ alternate_bases: string\n"
     ]
    }
   ],
   "source": [
    "# Get schema for the variants table\n",
    "try:\n",
    "    fields = client.get_schema_fields(\"virusseq\", \"collections.virusseq.variants\")\n",
    "    print(f\"üîç Variants table schema - {len(fields)} fields:\")\n",
    "    print()\n",
    "    \n",
    "    # Show first 15 fields\n",
    "    for i, field in enumerate(fields[:15], 1):\n",
    "        field_name = field['field']\n",
    "        field_type = field['type']\n",
    "        sql_type = field.get('sql_type', '')\n",
    "        \n",
    "        print(f\"   {i:2d}. {field_name:<25} | {field_type:<15} | {sql_type}\")\n",
    "    \n",
    "    if len(fields) > 15:\n",
    "        print(f\"   ... and {len(fields) - 15} more fields\")\n",
    "    \n",
    "    print(f\"\\nüìä Key fields we'll see in the data:\")\n",
    "    key_fields = ['pos', 'ref', 'alt', 'chrom', 'variant_id', 'sample_id']\n",
    "    for field in fields:\n",
    "        if any(key in field['field'].lower() for key in key_fields):\n",
    "            print(f\"   üîπ {field['field']}: {field['type']}\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to get schema: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "query-data"
   },
   "source": [
    "## üî¨ Query Variants Data\n",
    "\n",
    "Now let's query the variants table to get the first 10 rows of actual data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code",
    "id": "query-variants"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¨ Querying variants table...\n",
      "‚ö° This may take a moment as the query is processed asynchronously.\n",
      "\n",
      "‚ùå Query failed: Unexpected response format: []\n",
      "\n",
      "üîç Error details:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/54/75kj0vgs4hs2jh41xh7sbx4m0000gn/T/ipykernel_12300/2227833425.py\", line 8, in <module>\n",
      "    result = client.query(\n",
      "             ^^^^^^^^^^^^^\n",
      "  File \"/Users/mfiume/Documents/Development/omics-ai-cli/omics_ai/client.py\", line 331, in query\n",
      "    return self.query_with_polling(collection_slug, table_name, filters, limit, offset, order_by)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mfiume/Documents/Development/omics-ai-cli/omics_ai/client.py\", line 290, in query_with_polling\n",
      "    raise OmicsAIError(f\"Unexpected response format: {list(result.keys())}\")\n",
      "omics_ai.exceptions.OmicsAIError: Unexpected response format: []\n"
     ]
    }
   ],
   "source": [
    "# Query the first 10 rows from the variants table\n",
    "try:\n",
    "    print(\"üî¨ Querying variants table...\")\n",
    "    print(\"‚ö° This may take a moment as the query is processed asynchronously.\")\n",
    "    print()\n",
    "\n",
    "    print(\"Going in!\")\n",
    "    \n",
    "    # Use the standard query method from the library\n",
    "    result = client.query(\n",
    "        collection_slug=\"virusseq\", \n",
    "        table_name=\"collections.virusseq.variants\", \n",
    "        filters={},  # No filters - get all data\n",
    "        limit=10     # First 10 rows\n",
    "    )\n",
    "\n",
    "    print(\"Results:\")\n",
    "    print(result)\n",
    "    \n",
    "    # Extract the data\n",
    "    data = result.get('data', [])\n",
    "    pagination = result.get('pagination', {})\n",
    "    \n",
    "    print(f\"\\nüéâ Successfully retrieved {len(data)} variant records!\")\n",
    "    \n",
    "    if pagination:\n",
    "        total = pagination.get('total', 'Unknown')\n",
    "        print(f\"üìä Total variants in table: {total}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìã FIRST 10 VARIANT RECORDS:\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Display each variant record\n",
    "    for i, variant in enumerate(data, 1):\n",
    "        print(f\"\\nüîπ Variant {i}:\")\n",
    "        \n",
    "        # Show key fields first\n",
    "        key_fields = ['pos', 'ref', 'alt', 'chrom', 'variant_id', 'sample_id']\n",
    "        for key in key_fields:\n",
    "            if key in variant:\n",
    "                print(f\"   {key:<12}: {variant[key]}\")\n",
    "        \n",
    "        # Show a few other interesting fields\n",
    "        other_fields = ['quality', 'filter', 'info', 'genotype']\n",
    "        for key in other_fields:\n",
    "            if key in variant:\n",
    "                value = variant[key]\n",
    "                if isinstance(value, str) and len(value) > 50:\n",
    "                    value = value[:50] + \"...\"\n",
    "                print(f\"   {key:<12}: {value}\")\n",
    "        \n",
    "        # Show total number of fields in this record\n",
    "        print(f\"   üìè Total fields: {len(variant)}\")\n",
    "        \n",
    "        if i < len(data):\n",
    "            print(\"   \" + \"-\"*50)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Query failed: {e}\")\n",
    "    import traceback\n",
    "    print(\"\\nüîç Error details:\")\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "data-analysis"
   },
   "source": [
    "## üìà Convert to DataFrame\n",
    "\n",
    "Let's convert the variant data to a pandas DataFrame for easier analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab_type": "code",
    "id": "create-dataframe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå No data available to create DataFrame\n"
     ]
    }
   ],
   "source": [
    "# Convert to DataFrame if we have data\n",
    "try:\n",
    "    if 'data' in locals() and data:\n",
    "        # Create DataFrame\n",
    "        df = pd.DataFrame(data)\n",
    "        \n",
    "        print(f\"üìä Created DataFrame with {len(df)} rows and {len(df.columns)} columns\")\n",
    "        print()\n",
    "        \n",
    "        # Show basic info\n",
    "        print(\"üîç DataFrame Info:\")\n",
    "        print(f\"   Shape: {df.shape}\")\n",
    "        print(f\"   Columns: {len(df.columns)}\")\n",
    "        print()\n",
    "        \n",
    "        # Show column names\n",
    "        print(\"üìã Column Names:\")\n",
    "        for i, col in enumerate(df.columns[:20], 1):\n",
    "            print(f\"   {i:2d}. {col}\")\n",
    "        \n",
    "        if len(df.columns) > 20:\n",
    "            print(f\"   ... and {len(df.columns) - 20} more columns\")\n",
    "        \n",
    "        print()\n",
    "        \n",
    "        # Show first few rows with key columns\n",
    "        key_columns = []\n",
    "        for col in ['pos', 'ref', 'alt', 'chrom', 'variant_id', 'sample_id']:\n",
    "            if col in df.columns:\n",
    "                key_columns.append(col)\n",
    "        \n",
    "        if key_columns:\n",
    "            print(f\"üîπ Key columns preview:\")\n",
    "            print(df[key_columns].head())\n",
    "        else:\n",
    "            print(f\"üîπ First 5 columns preview:\")\n",
    "            print(df.iloc[:, :5].head())\n",
    "        \n",
    "    else:\n",
    "        print(\"‚ùå No data available to create DataFrame\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to create DataFrame: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "summary"
   },
   "source": [
    "## üéØ Summary\n",
    "\n",
    "**What we accomplished:**\n",
    "\n",
    "‚úÖ Connected to Viral AI network  \n",
    "‚úÖ Explored the VirusSeq collection  \n",
    "‚úÖ Examined the variants table schema  \n",
    "‚úÖ Successfully queried the first 10 variant records  \n",
    "‚úÖ Converted the data to a pandas DataFrame  \n",
    "\n",
    "**Next steps you could try:**\n",
    "- Query more data by increasing the `limit` parameter\n",
    "- Add filters to focus on specific chromosomes or positions\n",
    "- Analyze variant frequencies and distributions\n",
    "- Export the data for further analysis\n",
    "\n",
    "---\n",
    "\n",
    "ü¶† **Viral AI Variants Explorer** - Powered by [Omics AI Explorer](https://github.com/mfiume/omics-ai-python-library)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
