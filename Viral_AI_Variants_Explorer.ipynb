{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "title"
   },
   "source": [
    "# 🦠 Viral AI Variants Explorer\n",
    "\n",
    "This notebook demonstrates how to explore the **VirusSeq Variants** table on Viral AI using the Omics AI Explorer Python library.\n",
    "\n",
    "**Target Dataset**: `collections.virusseq.variants` on [viral.ai](https://viral.ai)\n",
    "\n",
    "## What we'll cover:\n",
    "- Connect to Viral AI network\n",
    "- Explore the VirusSeq collection\n",
    "- Query the variants table\n",
    "- Display the first 10 rows of variant data\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "setup"
   },
   "source": [
    "## 📦 Setup and Installation\n",
    "\n",
    "First, let's install and import the Omics AI Explorer library:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "install-package"
   },
   "outputs": [],
   "source": "# Install the Omics AI Explorer library\n!pip install git+https://github.com/mfiume/omics-ai-python-library.git --quiet\n\n# Import required libraries\ntry:\n    from omics_ai import OmicsAIClient\n    print(\"✅ Successfully imported OmicsAIClient!\")\nexcept ImportError:\n    print(\"⚠️ Package import failed, using fallback implementation...\")\n    \n    # Fallback implementation based on the working debug script\n    import requests\n    import json\n    import time\n    from typing import Dict, List, Optional, Any\n    from urllib.parse import quote\n    \n    def parse_json_lines_response(raw_text: str) -> Dict[str, Any]:\n        \"\"\"Parse JSON Lines response from Viral AI API.\"\"\"\n        if not raw_text.strip():\n            raise Exception(\"Empty response received\")\n        \n        # Split by lines and filter out empty lines\n        lines = [line.strip() for line in raw_text.strip().split('\\n') if line.strip()]\n        \n        if not lines:\n            raise Exception(\"No valid lines found in response\")\n        \n        # Parse each line as JSON\n        json_objects = []\n        for i, line in enumerate(lines):\n            try:\n                obj = json.loads(line)\n                json_objects.append(obj)\n            except json.JSONDecodeError as e:\n                if line != \"{}\":\n                    pass  # Silently ignore parsing errors\n        \n        if not json_objects:\n            raise Exception(\"No valid JSON objects found in response\")\n        \n        # Find the object with data (usually the last non-empty one)\n        for obj in reversed(json_objects):\n            if obj and 'data' in obj:\n                return obj\n        \n        # If no data object found, check for next_page_token (polling case)\n        for obj in reversed(json_objects):\n            if obj and 'next_page_token' in obj:\n                return obj\n        \n        # If we get here, we have only empty objects {} or unexpected format\n        if all(not obj for obj in json_objects):\n            return {\"next_page_token\": \"empty_response_poll\"}\n        \n        # Return the last non-empty object\n        non_empty_objects = [obj for obj in json_objects if obj]\n        if non_empty_objects:\n            return non_empty_objects[-1]\n        \n        raise Exception(f\"No data or next_page_token found. Objects: {json_objects}\")\n    \n    class OmicsAIClient:\n        \"\"\"Simplified Omics AI Explorer client for Viral AI.\"\"\"\n        \n        def __init__(self, network: str = \"viral.ai\"):\n            if not network.startswith(('http://', 'https://')):\n                network = f\"https://{network}\"\n            self.network = network.rstrip('/')\n            self.session = requests.Session()\n            self.session.headers.update({\n                'User-Agent': 'viral-ai-explorer/1.0',\n                'Accept': 'application/json',\n                'Content-Type': 'application/json'\n            })\n        \n        def _make_request(self, method: str, endpoint: str, **kwargs):\n            url = f\"{self.network}{endpoint}\"\n            response = self.session.request(method, url, **kwargs)\n            response.raise_for_status()\n            return response\n        \n        def list_collections(self) -> List[Dict[str, Any]]:\n            response = self._make_request('GET', '/api/collections')\n            return response.json()\n        \n        def list_tables(self, collection_slug: str) -> List[Dict[str, Any]]:\n            endpoint = f\"/api/collections/{quote(collection_slug)}/tables\"\n            response = self._make_request('GET', endpoint)\n            return response.json()\n        \n        def get_schema_fields(self, collection_slug: str, table_name: str) -> List[Dict[str, str]]:\n            endpoint = f\"/api/collection/{quote(collection_slug)}/data-connect/table/{quote(table_name)}/info\"\n            response = self._make_request('GET', endpoint)\n            schema = response.json()\n            \n            data_model = schema.get('data_model', {}).get('properties', {})\n            fields = []\n            for field_name, field_spec in data_model.items():\n                field_type = field_spec.get('type', '')\n                if isinstance(field_type, list):\n                    field_type = ', '.join(field_type)\n                if field_type == 'array' and 'items' in field_spec:\n                    item_type = field_spec['items'].get('type', '')\n                    if isinstance(item_type, list):\n                        item_type = ', '.join(item_type)\n                    field_type = f\"array<{item_type}>\"\n                \n                fields.append({\n                    'field': field_name,\n                    'type': field_type,\n                    'sql_type': field_spec.get('sqlType', '')\n                })\n            return fields\n        \n        def query(self, collection_slug: str, table_name: str, \n                 filters=None, limit: int = 100, offset: int = 0,\n                 max_polls: int = 10, poll_interval: float = 2.0) -> Dict[str, Any]:\n            \"\"\"Query with auto-polling for async results.\"\"\"\n            if filters is None:\n                filters = {}\n                \n            payload = {\n                \"tableName\": table_name,\n                \"filters\": filters,\n                \"pagination\": {\"limit\": limit, \"offset\": offset}\n            }\n            \n            endpoint = f\"/api/collections/{quote(collection_slug)}/tables/{quote(table_name)}/filter\"\n            \n            for poll_count in range(max_polls):\n                response = self._make_request('POST', endpoint, json=payload)\n                \n                # Parse response\n                try:\n                    result = parse_json_lines_response(response.text)\n                except Exception as e:\n                    raise Exception(f\"Failed to parse response: {e}\")\n                \n                # Check if we have data or need to poll\n                if 'data' in result and isinstance(result['data'], list):\n                    return result\n                elif 'next_page_token' in result or result.get('next_page_token') == 'empty_response_poll':\n                    if result.get('next_page_token') != 'empty_response_poll':\n                        payload['next_page_token'] = result['next_page_token']\n                    time.sleep(poll_interval)\n                else:\n                    return result  # Return whatever we got\n            \n            raise Exception(f\"Query timed out after {max_polls} polls\")\n    \n    print(\"✅ Using fallback implementation with working JSON Lines parser!\")\n\n# Import data analysis libraries\nimport pandas as pd\nfrom datetime import datetime\n\nprint(\"\\n🦠 Viral AI Variants Explorer Ready!\")\nprint(f\"📅 Started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "connect"
   },
   "source": [
    "## 🔗 Connect to Viral AI\n",
    "\n",
    "Let's connect to the Viral AI network and explore what's available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab_type": "code",
    "id": "connect-viral-ai"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔗 Connected to Viral AI!\n",
      "🌐 Network: https://viral.ai\n",
      "✅ Connection successful! Found 18 collections.\n",
      "\n",
      "🎯 Found VirusSeq collection:\n",
      "   📋 Name: VirusSeq SARS-CoV-2 Genome Sequences\n",
      "   🔗 Slug: virusseq\n",
      "   📝 Description: <p>The&nbsp;mission&nbsp;of&nbsp;Canadian&nbsp;COVID&nbsp;Genomics&nbsp;Network&nbsp;(<a href=\"https...\n"
     ]
    }
   ],
   "source": [
    "# Create client for Viral AI\n",
    "client = OmicsAIClient(\"viral.ai\")\n",
    "\n",
    "print(\"🔗 Connected to Viral AI!\")\n",
    "print(f\"🌐 Network: {client.network}\")\n",
    "\n",
    "# Test basic connection\n",
    "try:\n",
    "    collections = client.list_collections()\n",
    "    print(f\"✅ Connection successful! Found {len(collections)} collections.\")\n",
    "    \n",
    "    # Look for the virusseq collection\n",
    "    virusseq_collection = None\n",
    "    for collection in collections:\n",
    "        if collection.get('slugName') == 'virusseq':\n",
    "            virusseq_collection = collection\n",
    "            break\n",
    "    \n",
    "    if virusseq_collection:\n",
    "        print(f\"\\n🎯 Found VirusSeq collection:\")\n",
    "        print(f\"   📋 Name: {virusseq_collection.get('name', 'N/A')}\")\n",
    "        print(f\"   🔗 Slug: {virusseq_collection.get('slugName', 'N/A')}\")\n",
    "        print(f\"   📝 Description: {virusseq_collection.get('description', 'N/A')[:100]}...\")\n",
    "    else:\n",
    "        print(\"❌ VirusSeq collection not found\")\n",
    "        print(\"Available collections:\")\n",
    "        for collection in collections[:5]:\n",
    "            print(f\"   - {collection.get('name', 'Unnamed')} ({collection.get('slugName', 'no-slug')})\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"❌ Connection failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "explore-tables"
   },
   "source": [
    "## 📊 Explore VirusSeq Tables\n",
    "\n",
    "Now let's see what tables are available in the VirusSeq collection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab_type": "code",
    "id": "list-tables"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📋 Found 3 tables in VirusSeq collection:\n",
      "\n",
      "   1. variants\n",
      "      🔗 Table: collections.virusseq.variants\n",
      "      📏 Size: 42235025 rows\n",
      "      👆 This is our target table!\n",
      "\n",
      "   2. samples\n",
      "      🔗 Table: collections.virusseq.samples\n",
      "      📏 Size: 631138 rows\n",
      "\n",
      "   3. Files\n",
      "      🔗 Table: collections.virusseq._files\n",
      "      📏 Size: 1888810 rows\n",
      "\n",
      "🎯 Target table found: collections.virusseq.variants\n"
     ]
    }
   ],
   "source": [
    "# List tables in the virusseq collection\n",
    "try:\n",
    "    tables = client.list_tables(\"virusseq\")\n",
    "    print(f\"📋 Found {len(tables)} tables in VirusSeq collection:\")\n",
    "    print()\n",
    "    \n",
    "    variants_table = None\n",
    "    for i, table in enumerate(tables, 1):\n",
    "        table_name = table.get('qualified_table_name', table.get('name', 'Unknown'))\n",
    "        display_name = table.get('display_name', table_name)\n",
    "        size = table.get('size', 'Unknown')\n",
    "        \n",
    "        print(f\"   {i}. {display_name}\")\n",
    "        print(f\"      🔗 Table: {table_name}\")\n",
    "        print(f\"      📏 Size: {size} rows\")\n",
    "        \n",
    "        # Check if this is our target variants table\n",
    "        if 'variants' in table_name.lower():\n",
    "            variants_table = table\n",
    "            print(f\"      👆 This is our target table!\")\n",
    "        \n",
    "        print()\n",
    "    \n",
    "    if variants_table:\n",
    "        print(f\"🎯 Target table found: {variants_table.get('qualified_table_name')}\")\n",
    "    else:\n",
    "        print(\"❌ Variants table not found in the list\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"❌ Failed to list tables: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "schema"
   },
   "source": [
    "## 🔍 Explore Variants Table Schema\n",
    "\n",
    "Let's examine the structure (schema) of the variants table to understand what data is available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab_type": "code",
    "id": "get-schema"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Variants table schema - 5 fields:\n",
      "\n",
      "    1. start_position            | string          | bigint\n",
      "    2. end_position              | string          | bigint\n",
      "    3. reference_bases           | string          | varchar\n",
      "    4. alternate_bases           | string          | varchar\n",
      "    5. sequence_accession        | string          | varchar\n",
      "\n",
      "📊 Key fields we'll see in the data:\n",
      "   🔹 start_position: string\n",
      "   🔹 end_position: string\n",
      "   🔹 reference_bases: string\n",
      "   🔹 alternate_bases: string\n"
     ]
    }
   ],
   "source": [
    "# Get schema for the variants table\n",
    "try:\n",
    "    fields = client.get_schema_fields(\"virusseq\", \"collections.virusseq.variants\")\n",
    "    print(f\"🔍 Variants table schema - {len(fields)} fields:\")\n",
    "    print()\n",
    "    \n",
    "    # Show first 15 fields\n",
    "    for i, field in enumerate(fields[:15], 1):\n",
    "        field_name = field['field']\n",
    "        field_type = field['type']\n",
    "        sql_type = field.get('sql_type', '')\n",
    "        \n",
    "        print(f\"   {i:2d}. {field_name:<25} | {field_type:<15} | {sql_type}\")\n",
    "    \n",
    "    if len(fields) > 15:\n",
    "        print(f\"   ... and {len(fields) - 15} more fields\")\n",
    "    \n",
    "    print(f\"\\n📊 Key fields we'll see in the data:\")\n",
    "    key_fields = ['pos', 'ref', 'alt', 'chrom', 'variant_id', 'sample_id']\n",
    "    for field in fields:\n",
    "        if any(key in field['field'].lower() for key in key_fields):\n",
    "            print(f\"   🔹 {field['field']}: {field['type']}\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"❌ Failed to get schema: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "query-data"
   },
   "source": [
    "## 🔬 Query Variants Data\n",
    "\n",
    "Now let's query the variants table to get the first 10 rows of actual data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code",
    "id": "query-variants"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔬 Querying variants table...\n",
      "⚡ This may take a moment as the query is processed asynchronously.\n",
      "\n",
      "Going in!\n",
      "Results:\n",
      "{'data': [{'start_position': 10455, 'end_position': 10456, 'reference_bases': 'C', 'alternate_bases': 'T', 'sequence_accession': 'hCoV-19/Canada/AB-ABPHL-102772/2023'}, {'start_position': 10457, 'end_position': 10458, 'reference_bases': 'C', 'alternate_bases': 'T', 'sequence_accession': 'hCoV-19/Canada/BC-BCCDC-101979/2021'}, {'start_position': 10457, 'end_position': 10458, 'reference_bases': 'C', 'alternate_bases': 'T', 'sequence_accession': 'hCoV-19/Canada/BC-BCCDC-92384/2021'}, {'start_position': 10457, 'end_position': 10458, 'reference_bases': 'C', 'alternate_bases': 'T', 'sequence_accession': 'hCoV-19/Canada/BC-BCCDC-75322/2021'}, {'start_position': 10457, 'end_position': 10458, 'reference_bases': 'C', 'alternate_bases': 'T', 'sequence_accession': 'hCoV-19/Canada/BC-BCCDC-78406/2021'}, {'start_position': 10457, 'end_position': 10458, 'reference_bases': 'C', 'alternate_bases': 'T', 'sequence_accession': 'hCoV-19/Canada/BC-BCCDC-93803/2021'}, {'start_position': 10457, 'end_position': 10458, 'reference_bases': 'C', 'alternate_bases': 'T', 'sequence_accession': 'hCoV-19/Canada/BC-BCCDC-113415/2021'}, {'start_position': 10473, 'end_position': 10474, 'reference_bases': 'C', 'alternate_bases': 'T', 'sequence_accession': 'hCoV-19/Canada/MB-CPL-629515/2023'}, {'start_position': 10473, 'end_position': 10474, 'reference_bases': 'C', 'alternate_bases': 'T', 'sequence_accession': 'hCoV-19/Canada/BC-BCCDC-174387/2021'}, {'start_position': 10473, 'end_position': 10474, 'reference_bases': 'C', 'alternate_bases': 'T', 'sequence_accession': 'hCoV-19/Canada/MB-CPL-634595/2023'}], 'pagination': {'next_page_url': None, 'previous_page_url': None}, 'data_model': {'description': 'Automatically generated schema', '$schema': 'http://json-schema.org/draft-07/schema#', 'properties': {'start_position': {'format': 'bigint', 'type': 'int', '$comment': 'bigint'}, 'end_position': {'format': 'bigint', 'type': 'int', '$comment': 'bigint'}, 'reference_bases': {'format': 'varchar', 'type': 'string', '$comment': 'varchar'}, 'alternate_bases': {'format': 'varchar', 'type': 'string', '$comment': 'varchar'}, 'sequence_accession': {'format': 'varchar', 'type': 'string', '$comment': 'varchar'}}}}\n",
      "\n",
      "🎉 Successfully retrieved 10 variant records!\n",
      "📊 Total variants in table: Unknown\n",
      "\n",
      "================================================================================\n",
      "📋 FIRST 10 VARIANT RECORDS:\n",
      "================================================================================\n",
      "\n",
      "🔹 Variant 1:\n",
      "   📏 Total fields: 5\n",
      "   --------------------------------------------------\n",
      "\n",
      "🔹 Variant 2:\n",
      "   📏 Total fields: 5\n",
      "   --------------------------------------------------\n",
      "\n",
      "🔹 Variant 3:\n",
      "   📏 Total fields: 5\n",
      "   --------------------------------------------------\n",
      "\n",
      "🔹 Variant 4:\n",
      "   📏 Total fields: 5\n",
      "   --------------------------------------------------\n",
      "\n",
      "🔹 Variant 5:\n",
      "   📏 Total fields: 5\n",
      "   --------------------------------------------------\n",
      "\n",
      "🔹 Variant 6:\n",
      "   📏 Total fields: 5\n",
      "   --------------------------------------------------\n",
      "\n",
      "🔹 Variant 7:\n",
      "   📏 Total fields: 5\n",
      "   --------------------------------------------------\n",
      "\n",
      "🔹 Variant 8:\n",
      "   📏 Total fields: 5\n",
      "   --------------------------------------------------\n",
      "\n",
      "🔹 Variant 9:\n",
      "   📏 Total fields: 5\n",
      "   --------------------------------------------------\n",
      "\n",
      "🔹 Variant 10:\n",
      "   📏 Total fields: 5\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Query the first 10 rows from the variants table\n",
    "try:\n",
    "    print(\"🔬 Querying variants table...\")\n",
    "    print(\"⚡ This may take a moment as the query is processed asynchronously.\")\n",
    "    print()\n",
    "\n",
    "    # Use the standard query method from the library\n",
    "    result = client.query(\n",
    "        collection_slug=\"virusseq\", \n",
    "        table_name=\"collections.virusseq.variants\", \n",
    "        filters={},  # No filters - get all data\n",
    "        limit=10     # First 10 rows\n",
    "    )\n",
    "\n",
    "    # Extract the data\n",
    "    data = result.get('data', [])\n",
    "    pagination = result.get('pagination', {})\n",
    "    \n",
    "    print(f\"\\n🎉 Successfully retrieved {len(data)} variant records!\")\n",
    "    \n",
    "    if pagination:\n",
    "        total = pagination.get('total', 'Unknown')\n",
    "        print(f\"📊 Total variants in table: {total}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"📋 FIRST 10 VARIANT RECORDS:\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Display each variant record\n",
    "    for i, variant in enumerate(data, 1):\n",
    "        print(f\"\\n🔹 Variant {i}:\")\n",
    "        \n",
    "        # Show key fields first\n",
    "        key_fields = ['pos', 'ref', 'alt', 'chrom', 'variant_id', 'sample_id']\n",
    "        for key in key_fields:\n",
    "            if key in variant:\n",
    "                print(f\"   {key:<12}: {variant[key]}\")\n",
    "        \n",
    "        # Show a few other interesting fields\n",
    "        other_fields = ['quality', 'filter', 'info', 'genotype']\n",
    "        for key in other_fields:\n",
    "            if key in variant:\n",
    "                value = variant[key]\n",
    "                if isinstance(value, str) and len(value) > 50:\n",
    "                    value = value[:50] + \"...\"\n",
    "                print(f\"   {key:<12}: {value}\")\n",
    "        \n",
    "        # Show total number of fields in this record\n",
    "        print(f\"   📏 Total fields: {len(variant)}\")\n",
    "        \n",
    "        if i < len(data):\n",
    "            print(\"   \" + \"-\"*50)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Query failed: {e}\")\n",
    "    import traceback\n",
    "    print(\"\\n🔍 Error details:\")\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "data-analysis"
   },
   "source": [
    "## 📈 Convert to DataFrame\n",
    "\n",
    "Let's convert the variant data to a pandas DataFrame for easier analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab_type": "code",
    "id": "create-dataframe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Created DataFrame with 10 rows and 5 columns\n",
      "\n",
      "🔍 DataFrame Info:\n",
      "   Shape: (10, 5)\n",
      "   Columns: 5\n",
      "\n",
      "📋 Column Names:\n",
      "    1. start_position\n",
      "    2. end_position\n",
      "    3. reference_bases\n",
      "    4. alternate_bases\n",
      "    5. sequence_accession\n",
      "\n",
      "🔹 First 5 columns preview:\n",
      "   start_position  end_position reference_bases alternate_bases  \\\n",
      "0           10455         10456               C               T   \n",
      "1           10457         10458               C               T   \n",
      "2           10457         10458               C               T   \n",
      "3           10457         10458               C               T   \n",
      "4           10457         10458               C               T   \n",
      "\n",
      "                    sequence_accession  \n",
      "0  hCoV-19/Canada/AB-ABPHL-102772/2023  \n",
      "1  hCoV-19/Canada/BC-BCCDC-101979/2021  \n",
      "2   hCoV-19/Canada/BC-BCCDC-92384/2021  \n",
      "3   hCoV-19/Canada/BC-BCCDC-75322/2021  \n",
      "4   hCoV-19/Canada/BC-BCCDC-78406/2021  \n"
     ]
    }
   ],
   "source": [
    "# Convert to DataFrame if we have data\n",
    "try:\n",
    "    if 'data' in locals() and data:\n",
    "        # Create DataFrame\n",
    "        df = pd.DataFrame(data)\n",
    "        \n",
    "        print(f\"📊 Created DataFrame with {len(df)} rows and {len(df.columns)} columns\")\n",
    "        print()\n",
    "        \n",
    "        # Show basic info\n",
    "        print(\"🔍 DataFrame Info:\")\n",
    "        print(f\"   Shape: {df.shape}\")\n",
    "        print(f\"   Columns: {len(df.columns)}\")\n",
    "        print()\n",
    "        \n",
    "        # Show column names\n",
    "        print(\"📋 Column Names:\")\n",
    "        for i, col in enumerate(df.columns[:20], 1):\n",
    "            print(f\"   {i:2d}. {col}\")\n",
    "        \n",
    "        if len(df.columns) > 20:\n",
    "            print(f\"   ... and {len(df.columns) - 20} more columns\")\n",
    "        \n",
    "        print()\n",
    "        \n",
    "        # Show first few rows with key columns\n",
    "        key_columns = []\n",
    "        for col in ['pos', 'ref', 'alt', 'chrom', 'variant_id', 'sample_id']:\n",
    "            if col in df.columns:\n",
    "                key_columns.append(col)\n",
    "        \n",
    "        if key_columns:\n",
    "            print(f\"🔹 Key columns preview:\")\n",
    "            print(df[key_columns].head())\n",
    "        else:\n",
    "            print(f\"🔹 First 5 columns preview:\")\n",
    "            print(df.iloc[:, :5].head())\n",
    "        \n",
    "    else:\n",
    "        print(\"❌ No data available to create DataFrame\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"❌ Failed to create DataFrame: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "summary"
   },
   "source": [
    "## 🎯 Summary\n",
    "\n",
    "**What we accomplished:**\n",
    "\n",
    "✅ Connected to Viral AI network  \n",
    "✅ Explored the VirusSeq collection  \n",
    "✅ Examined the variants table schema  \n",
    "✅ Successfully queried the first 10 variant records  \n",
    "✅ Converted the data to a pandas DataFrame  \n",
    "\n",
    "**Next steps you could try:**\n",
    "- Query more data by increasing the `limit` parameter\n",
    "- Add filters to focus on specific chromosomes or positions\n",
    "- Analyze variant frequencies and distributions\n",
    "- Export the data for further analysis\n",
    "\n",
    "---\n",
    "\n",
    "🦠 **Viral AI Variants Explorer** - Powered by [Omics AI Explorer](https://github.com/mfiume/omics-ai-python-library)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}