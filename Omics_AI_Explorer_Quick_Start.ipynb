{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "omics-ai-title"
   },
   "source": [
    "# üß¨ Omics AI Explorer Python Library - Quick Start\n",
    "\n",
    "This notebook demonstrates how to use the Omics AI Explorer Python library to access genomics data across multiple Explorer networks including HiFi Solves, Neuroscience AI, and more.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/mfiume/omics-ai-python-library/blob/main/Omics_AI_Explorer_Quick_Start.ipynb)\n",
    "\n",
    "## üåü What You'll Learn\n",
    "\n",
    "- Install and import the Omics AI Explorer library\n",
    "- Connect to different Explorer networks\n",
    "- List available collections and tables\n",
    "- Inspect table schemas\n",
    "- Perform queries on genomics data\n",
    "- Work with real genomics datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## üì¶ Installation\n\nFirst, let's install the Omics AI Explorer library. We'll use a robust installation method that works reliably in Google Colab:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "installation"
   },
   "source": "# Install the Omics AI Explorer library\n# We'll download the source and install it directly to avoid build issues\n\nimport subprocess\nimport sys\nimport os\n\nprint(\"üß¨ Installing Omics AI Explorer Library\")\nprint(\"=\" * 50)\n\ntry:\n    # Method 1: Clone the repository\n    print(\"üì• Downloading source code...\")\n    if os.path.exists(\"omics-ai-python-library\"):\n        subprocess.run([\"rm\", \"-rf\", \"omics-ai-python-library\"], check=True)\n    \n    subprocess.run([\"git\", \"clone\", \"https://github.com/mfiume/omics-ai-python-library.git\"], check=True)\n    \n    # Method 2: Install dependencies first\n    print(\"\\nüì¶ Installing dependencies...\")\n    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"requests>=2.25.0\"], check=True)\n    \n    # Method 3: Install the package in development mode\n    print(\"\\nüîß Installing omics-ai-explorer...\")\n    os.chdir(\"omics-ai-python-library\")\n    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-e\", \".\"], check=True)\n    os.chdir(\"..\")\n    \n    print(\"\\n‚úÖ Omics AI Explorer library installed successfully!\")\n    \nexcept Exception as e:\n    print(f\"‚ùå Installation method 1 failed: {e}\")\n    print(\"\\nüîÑ Trying alternative installation...\")\n    \n    try:\n        # Fallback: Install just the core files manually\n        print(\"üì• Downloading core files...\")\n        import urllib.request\n        \n        base_url = \"https://raw.githubusercontent.com/mfiume/omics-ai-python-library/main/omics_ai\"\n        files = [\"__init__.py\", \"client.py\", \"exceptions.py\"]\n        \n        os.makedirs(\"omics_ai_local\", exist_ok=True)\n        \n        for file in files:\n            url = f\"{base_url}/{file}\"\n            urllib.request.urlretrieve(url, f\"omics_ai_local/{file}\")\n        \n        # Add the local package to path\n        sys.path.insert(0, \"/content\")\n        \n        print(\"‚úÖ Core files downloaded and configured!\")\n        \n    except Exception as e2:\n        print(f\"‚ùå Alternative installation also failed: {e2}\")\n        print(\"\\nüí° Manual solution: Will use inline implementation in next cell\")\n\n# Install visualization libraries\nprint(\"\\nüìä Installing visualization libraries...\")\nsubprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"pandas\", \"matplotlib\", \"seaborn\"], check=True)\n\nprint(\"\\nüéâ Setup complete! Ready to explore genomics data!\")",
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "install-package"
   },
   "outputs": [],
   "source": "# Import the Omics AI Explorer library with fallback options\n\ntry:\n    # Try normal import first\n    from omics_ai import OmicsAIClient\n    print(\"‚úÖ Successfully imported OmicsAIClient from installed package!\")\n    \nexcept ImportError:\n    print(\"‚ö†Ô∏è Package import failed, trying fallback method...\")\n    \n    try:\n        # Fallback: Add the cloned repository to path\n        import sys\n        sys.path.insert(0, '/content/omics-ai-python-library')\n        from omics_ai import OmicsAIClient\n        print(\"‚úÖ Successfully imported from cloned repository!\")\n        \n    except ImportError:\n        try:\n            # Try local files\n            sys.path.insert(0, '/content/omics_ai_local')\n            from client import OmicsAIClient\n            print(\"‚úÖ Successfully imported from downloaded files!\")\n        except ImportError:\n            print(\"‚ö†Ô∏è All import methods failed, using inline implementation...\")\n            \n            # Last resort: Define the client class inline\n            import requests\n            import json\n            import re\n            from typing import Dict, List, Optional, Any\n            from urllib.parse import quote\n            \n            class OmicsAIClient:\n                \"\"\"Simplified Omics AI Explorer client for Colab.\"\"\"\n                \n                KNOWN_NETWORKS = {\n                    \"hifisolves\": \"hifisolves.org\",\n                    \"neuroscience\": \"neuroscience.ai\", \n                    \"parkinsons\": \"cloud.parkinsonsroadmap.org\",\n                    \"biomedical\": \"biomedical.ai\"\n                }\n                \n                def __init__(self, network: str = \"hifisolves.org\", access_token: Optional[str] = None):\n                    if network in self.KNOWN_NETWORKS:\n                        network = self.KNOWN_NETWORKS[network]\n                    if not network.startswith(('http://', 'https://')):\n                        network = f\"https://{network}\"\n                        \n                    self.network = network.rstrip('/')\n                    self.access_token = access_token\n                    self.session = requests.Session()\n                    \n                    headers = {'User-Agent': 'omics-ai-colab-client', 'Accept': 'application/json'}\n                    if self.access_token:\n                        headers['Authorization'] = f'Bearer {self.access_token}'\n                    self.session.headers.update(headers)\n                \n                def _make_request(self, method: str, endpoint: str, **kwargs):\n                    url = f\"{self.network}{endpoint}\"\n                    response = self.session.request(method, url, **kwargs)\n                    response.raise_for_status()\n                    return response\n                \n                def list_collections(self) -> List[Dict[str, Any]]:\n                    response = self._make_request('GET', '/api/collections')\n                    return response.json()\n                \n                def list_tables(self, collection_slug: str) -> List[Dict[str, Any]]:\n                    endpoint = f\"/api/collections/{quote(collection_slug)}/tables\"\n                    response = self._make_request('GET', endpoint)\n                    return response.json()\n                \n                def get_schema_fields(self, collection_slug: str, table_name: str) -> List[Dict[str, str]]:\n                    endpoint = f\"/api/collection/{quote(collection_slug)}/data-connect/table/{quote(table_name)}/info\"\n                    response = self._make_request('GET', endpoint)\n                    schema = response.json()\n                    \n                    data_model = schema.get('data_model', {}).get('properties', {})\n                    fields = []\n                    for field_name, field_spec in data_model.items():\n                        field_type = field_spec.get('type', '')\n                        if isinstance(field_type, list):\n                            field_type = ', '.join(field_type)\n                        if field_type == 'array' and 'items' in field_spec:\n                            item_type = field_spec['items'].get('type', '')\n                            if isinstance(item_type, list):\n                                item_type = ', '.join(item_type)\n                            field_type = f\"array<{item_type}>\"\n                        \n                        fields.append({\n                            'field': field_name,\n                            'type': field_type,\n                            'sql_type': field_spec.get('sqlType', '')\n                        })\n                    return fields\n                \n                def query(self, collection_slug: str, table_name: str, limit: int = 100, **kwargs) -> Dict[str, Any]:\n                    payload = {\n                        \"tableName\": table_name,\n                        \"filters\": {},\n                        \"pagination\": {\"limit\": limit, \"offset\": 0}\n                    }\n                    \n                    endpoint = f\"/api/collections/{quote(collection_slug)}/tables/{quote(table_name)}/filter\"\n                    response = self._make_request('POST', endpoint, json=payload)\n                    \n                    raw_text = response.text\n                    json_objects = re.findall(r'\\{[^}]*\\}(?=\\s*\\{|\\s*$)', raw_text, re.DOTALL)\n                    if json_objects:\n                        return json.loads(json_objects[-1])\n                    return {'data': []}\n                \n                def count(self, collection_slug: str, table_name: str) -> int:\n                    endpoint = f\"/api/collections/{quote(collection_slug)}/tables/{quote(table_name)}/filter/count\"\n                    response = self._make_request('POST', endpoint, json={\"filters\": {}})\n                    \n                    raw_text = response.text\n                    json_objects = re.findall(r'\\{[^}]*\\}(?=\\s*\\{|\\s*$)', raw_text, re.DOTALL)\n                    if json_objects:\n                        result = json.loads(json_objects[-1])\n                        return result.get('count', 0)\n                    return 0\n            \n            print(\"‚úÖ Using inline client implementation!\")\n\n# Import additional libraries for data analysis\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom datetime import datetime\nimport json\n\n# Set up plotting style\nplt.style.use('default')\nsns.set_palette(\"husl\")\n\nprint(\"‚úÖ All imports successful!\")\nprint(f\"üìÖ Notebook run at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "import-and-setup"
   },
   "source": [
    "## üîß Import and Setup\n",
    "\n",
    "Now let's import the library and set up our environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imports"
   },
   "outputs": [],
   "source": [
    "# Import the Omics AI Explorer library\n",
    "from omics_ai import OmicsAIClient\n",
    "\n",
    "# Import additional libraries for data analysis\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úÖ All imports successful!\")\n",
    "print(f\"üìÖ Notebook run at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "network-exploration"
   },
   "source": [
    "## üåê Explore Multiple Networks\n",
    "\n",
    "The Omics AI Explorer library supports multiple networks. Let's explore what's available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "explore-networks"
   },
   "outputs": [],
   "source": [
    "# Available Explorer networks\n",
    "networks = {\n",
    "    \"HiFi Solves\": \"hifisolves\",\n",
    "    \"Biomedical AI\": \"biomedical\", \n",
    "    \"Neuroscience AI\": \"neuroscience\"\n",
    "}\n",
    "\n",
    "print(\"üåê Exploring Omics AI Explorer Networks\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "network_stats = {}\n",
    "\n",
    "for name, short_name in networks.items():\n",
    "    try:\n",
    "        print(f\"\\nüîó Connecting to {name}...\")\n",
    "        client = OmicsAIClient(short_name)\n",
    "        collections = client.list_collections()\n",
    "        \n",
    "        network_stats[name] = {\n",
    "            'collections': len(collections),\n",
    "            'client': client,\n",
    "            'sample_collections': collections[:3]  # Store first 3 for display\n",
    "        }\n",
    "        \n",
    "        print(f\"‚úÖ {name}: {len(collections)} collections found\")\n",
    "        \n",
    "        # Show sample collections\n",
    "        for i, collection in enumerate(collections[:3], 1):\n",
    "            print(f\"   {i}. {collection['name']} ({collection['slugName']})\")\n",
    "        \n",
    "        if len(collections) > 3:\n",
    "            print(f\"   ... and {len(collections) - 3} more collections\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå {name}: {e}\")\n",
    "        network_stats[name] = {'collections': 0, 'error': str(e)}\n",
    "\n",
    "# Summary\n",
    "print(f\"\\nüìä Network Summary:\")\n",
    "total_collections = sum(stats.get('collections', 0) for stats in network_stats.values())\n",
    "print(f\"   Total collections across all networks: {total_collections}\")\n",
    "\n",
    "for name, stats in network_stats.items():\n",
    "    if 'error' not in stats:\n",
    "        print(f\"   {name}: {stats['collections']} collections\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "visualize-networks"
   },
   "source": [
    "## üìä Visualize Network Statistics\n",
    "\n",
    "Let's create a visualization of the collections across networks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "plot-networks"
   },
   "outputs": [],
   "source": [
    "# Create a bar plot of collections per network\n",
    "network_names = []\n",
    "collection_counts = []\n",
    "\n",
    "for name, stats in network_stats.items():\n",
    "    if 'error' not in stats:\n",
    "        network_names.append(name)\n",
    "        collection_counts.append(stats['collections'])\n",
    "\n",
    "if network_names:  # Only plot if we have data\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bars = plt.bar(network_names, collection_counts, \n",
    "                   color=['#FF6B6B', '#4ECDC4', '#45B7D1'], alpha=0.8)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, count in zip(bars, collection_counts):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5, \n",
    "                str(count), ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    plt.title('üß¨ Collections Available Across Omics AI Explorer Networks', \n",
    "              fontsize=16, fontweight='bold', pad=20)\n",
    "    plt.ylabel('Number of Collections', fontsize=12)\n",
    "    plt.xlabel('Explorer Network', fontsize=12)\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"üìà Total: {sum(collection_counts)} collections across {len(network_names)} networks\")\nelse:\n",
    "    print(\"‚ö†Ô∏è No network data available for visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "quick-start-demo"
   },
   "source": [
    "## üöÄ Quick Start Demo\n",
    "\n",
    "Now let's replicate the Quick Start example from the README using the most accessible network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "quick-start"
   },
   "outputs": [],
   "source": [
    "# Choose the network with the most collections for our demo\n",
    "best_network = max(\n",
    "    [(name, stats) for name, stats in network_stats.items() if 'error' not in stats],\n",
    "    key=lambda x: x[1]['collections'],\n",
    "    default=(None, None)\n",
    ")\n",
    "\n",
    "if best_network[0]:\n",
    "    network_name, network_info = best_network\n",
    "    client = network_info['client']\n",
    "    \n",
    "    print(f\"üéØ Using {network_name} for Quick Start demo\")\n",
    "    print(f\"üìÇ {network_info['collections']} collections available\")\n",
    "    \n",
    "    # Get all collections\n",
    "    collections = client.list_collections()\n",
    "    \n",
    "    print(f\"\\nüìã First 5 collections:\")\n",
    "    for i, collection in enumerate(collections[:5], 1):\n",
    "        name = collection['name']\n",
    "        slug = collection['slugName']\n",
    "        description = collection.get('description', 'No description')\n",
    "        \n",
    "        # Clean up HTML and truncate description\n",
    "        import re\n",
    "        clean_desc = re.sub('<[^<]+?>', '', description)\n",
    "        clean_desc = clean_desc.replace('&nbsp;', ' ').strip()\n",
    "        if len(clean_desc) > 80:\n",
    "            clean_desc = clean_desc[:80] + \"...\"\n",
    "        \n",
    "        print(f\"   {i}. {name} ({slug})\")\n",
    "        print(f\"      {clean_desc}\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå No networks available for demo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "table-exploration"
   },
   "source": [
    "## üìä Table Exploration\n",
    "\n",
    "Let's find a collection with accessible tables and explore its structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "find-accessible-tables"
   },
   "outputs": [],
   "source": [
    "# Try to find collections with accessible tables\n",
    "accessible_collection = None\n",
    "accessible_tables = []\n",
    "\n",
    "if best_network[0]:\n",
    "    print(\"üîç Searching for accessible collections with tables...\")\n",
    "    \n",
    "    for collection in collections[:10]:  # Try first 10 collections\n",
    "        try:\n",
    "            collection_slug = collection['slugName']\n",
    "            print(f\"   Trying: {collection_slug}...\")\n",
    "            \n",
    "            tables = client.list_tables(collection_slug)\n",
    "            \n",
    "            if tables:  # Found tables!\n",
    "                accessible_collection = collection_slug\n",
    "                accessible_tables = tables\n",
    "                print(f\"   ‚úÖ Found {len(tables)} tables in '{collection_slug}'!\")\n",
    "                break\n",
    "            else:\n",
    "                print(f\"   ‚ö™ No tables in '{collection_slug}'\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå {collection_slug}: {str(e)[:50]}...\")\n",
    "            continue\n",
    "    \n",
    "    if accessible_collection:\n",
    "        print(f\"\\nüéâ Success! Using collection: {accessible_collection}\")\n",
    "        print(f\"üìä Found {len(accessible_tables)} tables:\")\n",
    "        \n",
    "        for i, table in enumerate(accessible_tables[:5], 1):\n",
    "            name = table.get('display_name', table.get('name', 'Unnamed'))\n",
    "            size = table.get('size', 'Unknown')\n",
    "            if isinstance(size, int):\n",
    "                size = f\"{size:,}\"\n",
    "            \n",
    "            print(f\"   {i}. {name}\")\n",
    "            print(f\"      ID: {table.get('qualified_table_name', 'N/A')}\")\n",
    "            print(f\"      Size: {size} rows\")\n",
    "            \n",
    "        if len(accessible_tables) > 5:\n",
    "            print(f\"   ... and {len(accessible_tables) - 5} more tables\")\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è No accessible tables found. This may be due to authentication requirements.\")\n",
    "        print(\"   Many collections require access tokens for full functionality.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "schema-inspection"
   },
   "source": [
    "## üî¨ Schema Inspection\n",
    "\n",
    "If we found accessible tables, let's examine their schema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "inspect-schema"
   },
   "outputs": [],
   "source": [
    "if accessible_collection and accessible_tables:\n",
    "    # Get schema for the first table\n",
    "    table = accessible_tables[0]\n",
    "    table_name = table['qualified_table_name']\n",
    "    \n",
    "    print(f\"üî¨ Inspecting schema for: {table.get('display_name', 'Table')}\")\n",
    "    print(f\"üìã Table ID: {table_name}\")\n",
    "    \n",
    "    try:\n",
    "        schema_fields = client.get_schema_fields(accessible_collection, table_name)\n",
    "        \n",
    "        print(f\"\\nüìä Found {len(schema_fields)} fields:\")\n",
    "        \n",
    "        # Create a DataFrame for better display\n",
    "        schema_df = pd.DataFrame(schema_fields)\n",
    "        \n",
    "        # Display first 10 fields\n",
    "        display_fields = schema_df.head(10)\n",
    "        \n",
    "        print(\"\\nüìã Field Details:\")\n",
    "        for i, (_, field) in enumerate(display_fields.iterrows(), 1):\n",
    "            print(f\"   {i:2d}. {field['field']:25} | {field['type']:15} | {field.get('sql_type', 'N/A')}\")\n",
    "        \n",
    "        if len(schema_fields) > 10:\n",
    "            print(f\"   ... and {len(schema_fields) - 10} more fields\")\n",
    "        \n",
    "        # Analyze field types\n",
    "        type_counts = schema_df['type'].value_counts()\n",
    "        print(f\"\\nüìà Field Type Distribution:\")\n",
    "        for field_type, count in type_counts.head().items():\n",
    "            print(f\"   {field_type}: {count} fields\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error getting schema: {e}\")\n",
    "        schema_fields = []\nelse:\n",
    "    print(\"‚ö†Ô∏è No accessible tables available for schema inspection\")\n",
    "    schema_fields = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data-querying"
   },
   "source": [
    "## üîé Data Querying\n",
    "\n",
    "Let's try to query some data and count rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "query-data"
   },
   "outputs": [],
   "source": [
    "if accessible_collection and accessible_tables:\n",
    "    table_name = accessible_tables[0]['qualified_table_name']\n",
    "    \n",
    "    print(f\"üîé Querying data from: {table_name}\")\n",
    "    \n",
    "    try:\n",
    "        # Try to count total rows\n",
    "        print(\"\\nüî¢ Counting total rows...\")\n",
    "        total_count = client.count(accessible_collection, table_name)\n",
    "        print(f\"   Total rows: {total_count:,}\")\n",
    "        \n",
    "        # Try to get a small sample of data\n",
    "        print(\"\\nüìã Fetching sample data (limit 3)...\")\n",
    "        results = client.query(\n",
    "            accessible_collection, \n",
    "            table_name, \n",
    "            limit=3\n",
    "        )\n",
    "        \n",
    "        if results.get('data'):\n",
    "            sample_data = results['data']\n",
    "            print(f\"   ‚úÖ Retrieved {len(sample_data)} sample rows\")\n",
    "            \n",
    "            # Display sample data structure\n",
    "            if sample_data:\n",
    "                first_row = sample_data[0]\n",
    "                print(f\"   üìä Sample row has {len(first_row)} fields\")\n",
    "                print(f\"   üè∑Ô∏è  Field names: {list(first_row.keys())[:5]}{'...' if len(first_row) > 5 else ''}\")\n",
    "                \n",
    "                # Show first few field values from first row\n",
    "                print(f\"\\n   üìù Sample values from first row:\")\n",
    "                for i, (key, value) in enumerate(list(first_row.items())[:5]):\n",
    "                    # Truncate long values\n",
    "                    if isinstance(value, str) and len(str(value)) > 50:\n",
    "                        value = str(value)[:50] + \"...\"\n",
    "                    print(f\"      {key}: {value}\")\n",
    "                    \n",
    "        else:\n",
    "            print(\"   ‚ö™ Query successful but no data returned\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Query error: {e}\")\n",
    "        print(\"   üí° This might be due to access restrictions or authentication requirements\")\nelse:\n",
    "    print(\"‚ö†Ô∏è No accessible tables available for querying\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "authentication-demo"
   },
   "source": [
    "## üîê Authentication Demo\n",
    "\n",
    "Many collections require authentication. Here's how to use access tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "auth-demo"
   },
   "outputs": [],
   "source": [
    "print(\"üîê Authentication Features Demo\")\nprint(\"=\" * 40)\n\n# Demo authentication methods (don't use real tokens in notebooks!)\nif best_network[0]:\n    client = network_info['client']\n    \n    print(\"\\nüîß Authentication Methods:\")\n    print(\"\\n1. Setting an access token:\")\n    print(\"   client.set_access_token('your-token-here')\")\n    \n    print(\"\\n2. Creating client with token:\")\n    print(\"   client = OmicsAIClient('hifisolves', access_token='your-token')\")\n    \n    print(\"\\n3. Clearing authentication:\")\n    print(\"   client.clear_access_token()\")\n    \n    # Demonstrate token management (with fake token)\n    print(\"\\nüß™ Demo with placeholder token:\")\n    client.set_access_token(\"demo-token-placeholder\")\n    print(\"   ‚úÖ Token set successfully\")\n    \n    client.clear_access_token() \n    print(\"   ‚úÖ Token cleared successfully\")\n    \n    print(\"\\nüí° To get real access tokens:\")\n    print(\"   ‚Ä¢ Visit the Explorer network's authentication page\")\n    print(\"   ‚Ä¢ Generate an API token or use OAuth flow\")\n    print(\"   ‚Ä¢ Keep tokens secure and never commit them to code!\")\nelse:\n    print(\"‚ö†Ô∏è No network available for authentication demo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "advanced-example"
   },
   "source": [
    "## üöÄ Advanced Example: Network Comparison\n",
    "\n",
    "Let's create a comprehensive comparison of the networks we can access:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "network-comparison"
   },
   "outputs": [],
   "source": [
    "print(\"üìä Comprehensive Network Analysis\")\nprint(\"=\" * 50)\n\n# Collect detailed statistics\ndetailed_stats = []\n\nfor name, stats in network_stats.items():\n    if 'error' not in stats:\n        try:\n            client = stats['client']\n            collections = client.list_collections()\n            \n            # Try to count accessible tables\n            accessible_collections = 0\n            total_tables = 0\n            \n            for collection in collections[:5]:  # Sample first 5\n                try:\n                    tables = client.list_tables(collection['slugName'])\n                    if tables:\n                        accessible_collections += 1\n                        total_tables += len(tables)\n                except:\n                    pass\n            \n            detailed_stats.append({\n                'Network': name,\n                'Collections': len(collections),\n                'Accessible Collections (sample)': accessible_collections,\n                'Total Tables (sample)': total_tables,\n                'Avg Tables per Collection': round(total_tables / max(accessible_collections, 1), 1)\n            })\n            \n        except Exception as e:\n            detailed_stats.append({\n                'Network': name,\n                'Collections': stats.get('collections', 0),\n                'Error': str(e)[:30] + \"...\"\n            })\n\nif detailed_stats:\n    # Create and display comparison table\n    comparison_df = pd.DataFrame(detailed_stats)\n    \n    print(\"\\nüìã Network Comparison Table:\")\n    print(comparison_df.to_string(index=False))\n    \n    # Create visualization if we have numeric data\n    numeric_df = comparison_df.select_dtypes(include='number')\n    if not numeric_df.empty and len(numeric_df) > 1:\n        \n        plt.figure(figsize=(12, 8))\n        \n        # Create subplots for different metrics\n        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n        fig.suptitle('üß¨ Omics AI Explorer Networks - Detailed Analysis', fontsize=16, fontweight='bold')\n        \n        # Plot 1: Collections per network\n        if 'Collections' in comparison_df.columns:\n            axes[0, 0].bar(comparison_df['Network'], comparison_df['Collections'], \n                          color=['#FF6B6B', '#4ECDC4', '#45B7D1'])\n            axes[0, 0].set_title('Total Collections')\n            axes[0, 0].set_ylabel('Count')\n            \n        # Plot 2: Accessible collections\n        if 'Accessible Collections (sample)' in comparison_df.columns:\n            axes[0, 1].bar(comparison_df['Network'], comparison_df['Accessible Collections (sample)'], \n                          color=['#96CEB4', '#FFEAA7', '#DDA0DD'])\n            axes[0, 1].set_title('Accessible Collections (Sample)')\n            axes[0, 1].set_ylabel('Count')\n            \n        # Plot 3: Total tables\n        if 'Total Tables (sample)' in comparison_df.columns:\n            axes[1, 0].bar(comparison_df['Network'], comparison_df['Total Tables (sample)'], \n                          color=['#A8E6CF', '#88D8C0', '#78C7C2'])\n            axes[1, 0].set_title('Total Tables (Sample)')\n            axes[1, 0].set_ylabel('Count')\n            \n        # Plot 4: Average tables per collection\n        if 'Avg Tables per Collection' in comparison_df.columns:\n            axes[1, 1].bar(comparison_df['Network'], comparison_df['Avg Tables per Collection'], \n                          color=['#FFD93D', '#6BCF7F', '#4D96FF'])\n            axes[1, 1].set_title('Avg Tables per Collection')\n            axes[1, 1].set_ylabel('Average')\n            \n        plt.tight_layout()\n        plt.show()\n        \nelse:\n    print(\"‚ö†Ô∏è No network data available for detailed analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "summary-and-next-steps"
   },
   "source": [
    "## üéâ Summary and Next Steps\n",
    "\n",
    "Congratulations! You've successfully explored the Omics AI Explorer Python library. Here's what you've accomplished:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "summary"
   },
   "outputs": [],
   "source": [
    "print(\"üéâ OMICS AI EXPLORER QUICK START SUMMARY\")\nprint(\"=\" * 60)\n\nsuccesses = []\nif network_stats:\n    total_networks = len([name for name, stats in network_stats.items() if 'error' not in stats])\n    total_collections = sum(stats.get('collections', 0) for stats in network_stats.values() if 'error' not in stats)\n    \n    successes.extend([\n        f\"‚úÖ Connected to {total_networks} Explorer networks\",\n        f\"‚úÖ Discovered {total_collections} total collections\",\n        \"‚úÖ Successfully imported and used the library\"\n    ])\n\nif accessible_collection:\n    successes.extend([\n        f\"‚úÖ Found accessible collection: {accessible_collection}\",\n        f\"‚úÖ Listed {len(accessible_tables)} tables\"\n    ])\n\nif schema_fields:\n    successes.extend([\n        f\"‚úÖ Inspected table schema ({len(schema_fields)} fields)\",\n        \"‚úÖ Analyzed field types and structure\"\n    ])\n\nsuccesses.extend([\n    \"‚úÖ Demonstrated authentication features\",\n    \"‚úÖ Created data visualizations\",\n    \"‚úÖ Performed network comparison analysis\"\n])\n\nfor success in successes:\n    print(success)\n\nprint(\"\\nüöÄ WHAT'S NEXT?\")\nprint(\"-\" * 30)\nprint(\"üìö Learn More:\")\nprint(\"   ‚Ä¢ Explore the full documentation on GitHub\")\nprint(\"   ‚Ä¢ Try the advanced examples in the repository\")\nprint(\"   ‚Ä¢ Check out HiFi Solves specific features\")\n\nprint(\"\\nüîê Get Access:\")\nprint(\"   ‚Ä¢ Request access tokens for protected collections\")\nprint(\"   ‚Ä¢ Explore authentication workflows\")\nprint(\"   ‚Ä¢ Join the genomics data community\")\n\nprint(\"\\nüõ†Ô∏è Build Something:\")\nprint(\"   ‚Ä¢ Create your own genomics analysis workflows\")\nprint(\"   ‚Ä¢ Integrate with other bioinformatics tools\")\nprint(\"   ‚Ä¢ Contribute to the open source project\")\n\nprint(\"\\nüìû Get Help:\")\nprint(\"   ‚Ä¢ GitHub Issues: https://github.com/mfiume/omics-ai-python-library/issues\")\nprint(\"   ‚Ä¢ Documentation: https://github.com/mfiume/omics-ai-python-library#readme\")\nprint(\"   ‚Ä¢ Community: Join the discussions on GitHub\")\n\nprint(f\"\\nüéØ Total Success Rate: {len(successes)}/10 features demonstrated\")\nprint(\"\\nüåü Happy exploring with Omics AI! üß¨\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "additional-resources"
   },
   "source": [
    "## üìö Additional Resources\n",
    "\n",
    "### üîó Links\n",
    "- **GitHub Repository**: [mfiume/omics-ai-python-library](https://github.com/mfiume/omics-ai-python-library)\n",
    "- **HiFi Solves**: [hifisolves.org](https://hifisolves.org)\n",
    "- **Neuroscience AI**: [neuroscience.ai](https://neuroscience.ai)\n",
    "- **Biomedical AI**: [biomedical.ai](https://biomedical.ai)\n",
    "\n",
    "### üìñ Documentation Sections\n",
    "- **Basic Usage**: Simple queries and data access\n",
    "- **Advanced Queries**: Complex filtering and pagination\n",
    "- **Authentication**: Working with protected collections\n",
    "- **API Reference**: Complete method documentation\n",
    "\n",
    "### üí° Tips for Success\n",
    "1. **Start Simple**: Begin with public collections before moving to authenticated ones\n",
    "2. **Explore Schemas**: Always check table schemas before querying\n",
    "3. **Handle Errors**: Many collections require specific permissions\n",
    "4. **Use Pagination**: For large datasets, use limit and offset parameters\n",
    "5. **Stay Updated**: Check the GitHub repository for new features and updates\n",
    "\n",
    "---\n",
    "\n",
    "**Ready to dive deeper into genomics data analysis? Clone the repository and explore more examples!** üöÄ"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}